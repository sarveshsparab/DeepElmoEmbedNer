{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%html\n",
    "<style> \n",
    "    table {display: block;} \n",
    "</style>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep contextualized word representations\n",
    "## Matthew E. Peters, Mark Neumann, Mohit Iyyer, Matt Gardner, Christopher Clark, Kenton Lee and Luke Zettlemoyer\n",
    "### Code\n",
    "- https://github.com/blackbbc/NER\n",
    "- https://github.com/sarveshsparab/DeepElmoEmbedNer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installing the required dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow\n",
    "!pip install numpy\n",
    "!pip install tqdm\n",
    "!pip install gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding paths to sys paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "sys.path.append('../model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Supressing warning level messages in output "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiating an object of the NER parent class implementation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from main import DeepElmoEmbedNer\n",
    "\n",
    "deen = DeepElmoEmbedNer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiating the input files for the model\n",
    "### 3 files required\n",
    "- train : For the model to train\n",
    "- dev : For the model to validate the training\n",
    "- test : To evaluate the performance to the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_dict = dict()\n",
    "file_dict['train'] = '../data/sample/ner_test_input.txt'\n",
    "file_dict['test'] = '../data/sample/ner_test_input.txt'\n",
    "file_dict['dev'] = '../data/sample/ner_test_input.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading from the dataset\n",
    "- Description\n",
    "    * Reads a dataset in preparation for train or test. Returns data in proper format for train or test.\n",
    "- Returns\n",
    "    * A dictionary of file_dict keys as keys and values as lists of lines, where in each line is further tokenized on the column delimiter and extracted as a list\n",
    "- Arguments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    "    <thead>\n",
    "        <tr>\n",
    "            <th>Type</th>\n",
    "            <th>Name</th>\n",
    "            <th>Default</th>\n",
    "            <th>Purpose</th>\n",
    "            <th>Required</th>\n",
    "        </tr>\n",
    "    </thead>\n",
    "    <tbody>\n",
    "        <tr>\n",
    "            <td rowspan=\"2\">Standard</td>\n",
    "            <td>file_dict</td>\n",
    "            <td>-</td>\n",
    "            <td>A dictionary with input file locations</td>\n",
    "            <td>✔</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>dataset_name</td>\n",
    "            <td>CoNLL03</td>\n",
    "            <td>Name of the dataset required for calling appropriate utils, converters</td>\n",
    "            <td>✔</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>args</td>\n",
    "            <td>N/A</td>\n",
    "            <td>None</td>\n",
    "            <td>N/A</td>\n",
    "            <td>✖</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td rowspan=\"2\">kwargs</td>\n",
    "            <td>fileHasHeaders</td>\n",
    "            <td>True</td>\n",
    "            <td>Flag to check if input file has headers</td>\n",
    "            <td>✖</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>columnDelimiter</td>\n",
    "            <td>`space`</td>\n",
    "            <td>Delimiter in the data input</td>\n",
    "            <td>✖</td>\n",
    "        </tr>\n",
    "    </tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[main.py:150 - read_dataset() ] Invoked read_dataset method\n",
      "[main.py:151 - read_dataset() ] With parameters : \n",
      "[main.py:152 - read_dataset() ] {'train': '../data/sample/ner_test_input.txt', 'test': '../data/sample/ner_test_input.txt', 'dev': '../data/sample/ner_test_input.txt'}\n",
      "[main.py:153 - read_dataset() ] CoNLL2003\n",
      "[main.py:154 - read_dataset() ] (None,)\n",
      "[main.py:155 - read_dataset() ] {}\n"
     ]
    }
   ],
   "source": [
    "data = deen.read_dataset(file_dict, \"CoNLL2003\", None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting the ground truth data\n",
    "- Description\n",
    "    * Converts test data into common format for evaluation \\[i.e. same format as predict()\\] \n",
    "    * This added step/layer of abstraction is required due to the refactoring of read_dataset_train() and read_dataset_test() back to the single method of read_dataset() along with the requirement on the format of the output of predict() and therefore the input format requirement of evaluate()\n",
    "- Returns\n",
    "    * \\[tuple,...\\], i.e. list of tuples. \\[SAME format as output of predict()\\]\n",
    "    * Each tuple is (start index, span, mention text, mention type)\n",
    "    * Where:\n",
    "         - start index: int, the index of the first character of the mention span. None if not applicable.\n",
    "         - span: int, the length of the mention. None if not applicable.\n",
    "         - mention text: str, the actual text that was identified as a named entity. Required.\n",
    "         - mention type: str, the entity/mention type. None if not applicable.\n",
    "- Arguments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    "    <thead>\n",
    "        <tr>\n",
    "            <th>Type</th>\n",
    "            <th>Name</th>\n",
    "            <th>Default</th>\n",
    "            <th>Purpose</th>\n",
    "            <th>Required</th>\n",
    "        </tr>\n",
    "    </thead>\n",
    "    <tbody>\n",
    "        <tr>\n",
    "            <td>Standard</td>\n",
    "            <td>data</td>\n",
    "            <td>-</td>\n",
    "            <td>data in proper format for train or test. [i.e. format of output from read_dataset]</td>\n",
    "            <td>✔</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>args</td>\n",
    "            <td>N/A</td>\n",
    "            <td>None</td>\n",
    "            <td>N/A</td>\n",
    "            <td>✖</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td rowspan=\"4\">kwargs</td>\n",
    "            <td>wordPosition</td>\n",
    "            <td>0</td>\n",
    "            <td>Column number with the mention word</td>\n",
    "            <td>✖</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>tagPosition</td>\n",
    "            <td>3</td>\n",
    "            <td>Column number with the entity tag</td>\n",
    "            <td>✖</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>writeGroundTruthToFile</td>\n",
    "            <td>True</td>\n",
    "            <td>Flag to enable writing ground truths to a file</td>\n",
    "            <td>✖</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>groundTruthPath</td>\n",
    "            <td>../results/groundTruths.txt</td>\n",
    "            <td>Location to save the ground truths file</td>\n",
    "            <td>✖</td>\n",
    "        </tr>\n",
    "    </tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[main.py:93 - convert_ground_truth() ] Invoked convert_ground_truth method\n",
      "[main.py:94 - convert_ground_truth() ] With parameters : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[main.py:95 - convert_ground_truth() ] {'train': [['Yes', 'UH', '(TOP(S(INTJ*)', 'O', 'bc/cnn/00/cnn_0003', '0', '0', '-', '-', '-', 'Linda_Hamilton', '*', '-'], ['they', 'PRP', '(NP*)', 'O', 'bc/cnn/00/cnn_0003', '0', '1', '-', '-', '-', 'Linda_Hamilton', '*', '(15)'], ['did', 'VBD', '(VP*)', 'O', 'bc/cnn/00/cnn_0003', '0', '2', 'do', '01', '-', 'Linda_Hamilton', '(V*)', '-'], ['/.', '.', '*))', 'O', 'bc/cnn/00/cnn_0003', '0', '3', '-', '-', '-', 'Linda_Hamilton', '*', '-'], [], ['and', 'CC', '(TOP(S*', 'O', 'bc/cnn/00/cnn_0003', '0', '0', '-', '-', '-', 'Linda_Hamilton', '(ARGM-DIS*)', '*', '-'], ['they', 'PRP', '(NP*)', 'O', 'bc/cnn/00/cnn_0003', '0', '1', '-', '-', '-', 'Linda_Hamilton', '(ARG1*)', '*', '(15)'], ['were', 'VBD', '(VP*', 'O', 'bc/cnn/00/cnn_0003', '0', '2', 'be', '01', '2', 'Linda_Hamilton', '(V*)', '*', '-'], ['not', 'RB', '*', 'O', 'bc/cnn/00/cnn_0003', '0', '3', '-', '-', '-', 'Linda_Hamilton', '(ARGM-NEG*)', '*', '-'], ['the', 'DT', '(NP(NP*', 'O', 'bc/cnn/00/cnn_0003', '0', '4', '-', '-', '-', 'Linda_Hamilton', '(ARG2*', '(ARG1*', '-'], ['first', 'JJ', '*', 'B-ORDINAL', 'bc/cnn/00/cnn_0003', '0', '5', '-', '-', '-', 'Linda_Hamilton', '*', '*', '-'], ['company', 'NN', '*)', 'O', 'bc/cnn/00/cnn_0003', '0', '6', 'company', '-', '1', 'Linda_Hamilton', '*', '*)', '-'], ['that', 'WDT', '(SBAR(WHNP*)', 'O', 'bc/cnn/00/cnn_0003', '0', '7', '-', '-', '-', 'Linda_Hamilton', '*', '(R-ARG1*)', '-'], ['approached', 'VBD', '(S(VP*', 'O', 'bc/cnn/00/cnn_0003', '0', '8', 'approach', '01', '2', 'Linda_Hamilton', '*', '(V*)', '-'], ['me', 'PRP', '(NP*))))))', 'O', 'bc/cnn/00/cnn_0003', '0', '9', '-', '-', '-', 'Linda_Hamilton', '*)', '(ARG2*)', '(76)'], ['/.', '.', '*))', 'O', 'bc/cnn/00/cnn_0003', '0', '10', '-', '-', '-', 'Linda_Hamilton', '*', '*', '-'], [], ['but', 'CC', '(TOP(S*', 'O', 'bc/cnn/00/cnn_0003', '0', '0', '-', '-', '-', 'Linda_Hamilton', '*', '*', '-'], ['I', 'PRP', '(S(NP*)', 'O', 'bc/cnn/00/cnn_0003', '0', '1', '-', '-', '-', 'Linda_Hamilton', '*', '(ARG0*)', '(76)'], ['am', 'VBP', '(VP*', 'O', 'bc/cnn/00/cnn_0003', '0', '2', 'be', '03', '-', 'Linda_Hamilton', '(V*)', '*', '-'], ['not', 'RB', '*', 'O', 'bc/cnn/00/cnn_0003', '0', '3', '-', '-', '-', 'Linda_Hamilton', '*', '(ARGM-NEG*)', '-'], ['selling', 'VBG', '(VP*', 'O', 'bc/cnn/00/cnn_0003', '0', '4', 'sell', '01', '1', 'Linda_Hamilton', '*', '(V*)', '-'], ['medicine', 'NN', '(NP*', 'O', 'bc/cnn/00/cnn_0003', '0', '5', 'medicine', '-', '1', 'Linda_Hamilton', '*', '(ARG1*', '-'], ['or', 'CC', '*', 'O', 'bc/cnn/00/cnn_0003', '0', '6', '-', '-', '-', 'Linda_Hamilton', '*', '*', '-'], ['pharmaceuticals', 'NNS', '*))))', 'O', 'bc/cnn/00/cnn_0003', '0', '7', '-', '-', '-', 'Linda_Hamilton', '*', '*)', '-'], ['/.', '.', '*))', 'O', 'bc/cnn/00/cnn_0003', '0', '8', '-', '-', '-', 'Linda_Hamilton', '*', '*', '-'], [], ['I', 'PRP', '(TOP(S(NP*)', 'O', 'bc/cnn/00/cnn_0003', '0', '0', '-', '-', '-', 'Linda_Hamilton', '(ARG1*)', '*', '*', '(76)'], [\"'m\", 'VBP', '(VP*', 'O', 'bc/cnn/00/cnn_0003', '0', '1', 'be', '01', '1', 'Linda_Hamilton', '(V*)', '*', '*', '-'], ['sort', 'RB', '(PP(ADVP*', 'O', 'bc/cnn/00/cnn_0003', '0', '2', '-', '-', '-', 'Linda_Hamilton', '(ARG2*', '*', '*', '-'], ['of', 'RB', '*)', 'O', 'bc/cnn/00/cnn_0003', '0', '3', '-', '-', '-', 'Linda_Hamilton', '*', '*', '*', '-'], ['about', 'IN', '*', 'O', 'bc/cnn/00/cnn_0003', '0', '4', '-', '-', '-', 'Linda_Hamilton', '*', '*', '*', '-'], ['selling', 'VBG', '(S(VP*', 'O', 'bc/cnn/00/cnn_0003', '0', '5', 'sell', '01', '2', 'Linda_Hamilton', '*', '(V*)', '*', '-'], ['a', 'DT', '(NP(NP*', 'O', 'bc/cnn/00/cnn_0003', '0', '6', '-', '-', '-', 'Linda_Hamilton', '*', '(ARG1*', '*', '-'], ['full', 'JJ', '(ADJP*', 'O', 'bc/cnn/00/cnn_0003', '0', '7', '-', '-', '-', 'Linda_Hamilton', '*', '*', '(ARG2*', '-'], ['body', 'NN', '*)', 'O', 'bc/cnn/00/cnn_0003', '0', '8', 'body', '-', '2', 'Linda_Hamilton', '*', '*', '*)', '-'], ['approach', 'NN', '*)', 'O', 'bc/cnn/00/cnn_0003', '0', '9', 'approach', '02', '3', 'Linda_Hamilton', '*', '*', '(V*)', '-'], ['to', 'IN', '(PP*', 'O', 'bc/cnn/00/cnn_0003', '0', '10', '-', '-', '-', 'Linda_Hamilton', '*', '*', '(ARG1*', '-'], ['wellness', 'NN', '(NP*)))))))', 'O', 'bc/cnn/00/cnn_0003', '0', '11', '-', '-', '-', 'Linda_Hamilton', '*)', '*)', '*)', '-'], ['/.', '.', '*))', 'O', 'bc/cnn/00/cnn_0003', '0', '12', '-', '-', '-', 'Linda_Hamilton', '*', '*', '*', '-'], [], ['Um', 'UH', '(TOP(S(INTJ*)', 'O', 'bc/cnn/00/cnn_0003', '0', '0', '-', '-', '-', 'Linda_Hamilton', '(ARGM-DIS*)', '*', '-'], ['there', 'EX', '(NP*)', 'O', 'bc/cnn/00/cnn_0003', '0', '1', '-', '-', '-', 'Linda_Hamilton', '*', '*', '-'], [\"'s\", 'VBZ', '(VP*', 'O', 'bc/cnn/00/cnn_0003', '0', '2', 'be', '02', '3', 'Linda_Hamilton', '(V*)', '*', '-'], ['a', 'DT', '(NP(NP*', 'O', 'bc/cnn/00/cnn_0003', '0', '3', '-', '-', '-', 'Linda_Hamilton', '(ARG1*', '*', '-'], ['big', 'JJ', '*', 'O', 'bc/cnn/00/cnn_0003', '0', '4', '-', '-', '-', 'Linda_Hamilton', '*', '*', '-'], ['gap', 'NN', '*)', 'O', 'bc/cnn/00/cnn_0003', '0', '5', 'gap', '-', '4', 'Linda_Hamilton', '*', '*', '-'], ['between', 'IN', '(PP*', 'O', 'bc/cnn/00/cnn_0003', '0', '6', '-', '-', '-', 'Linda_Hamilton', '*', '*', '-'], ['those', 'DT', '(NP(NP(NP*)', 'O', 'bc/cnn/00/cnn_0003', '0', '7', '-', '-', '-', 'Linda_Hamilton', '*', '(ARG1*)', '-'], ['that', 'WDT', '(SBAR(WHNP*)', 'O', 'bc/cnn/00/cnn_0003', '0', '8', '-', '-', '-', 'Linda_Hamilton', '*', '(R-ARG1*)', '-'], ['are', 'VBP', '(S(VP*', 'O', 'bc/cnn/00/cnn_0003', '0', '9', 'be', '01', '1', 'Linda_Hamilton', '*', '(V*)', '-'], ['mentally', 'RB', '(ADJP*', 'O', 'bc/cnn/00/cnn_0003', '0', '10', '-', '-', '-', 'Linda_Hamilton', '*', '(ARG2*', '-'], ['ill', 'JJ', '*)))))', 'O', 'bc/cnn/00/cnn_0003', '0', '11', '-', '-', '-', 'Linda_Hamilton', '*', '*)', '-'], ['and', 'CC', '*', 'O', 'bc/cnn/00/cnn_0003', '0', '12', '-', '-', '-', 'Linda_Hamilton', '*', '*', '-'], ['the', 'DT', '(NP*', 'O', 'bc/cnn/00/cnn_0003', '0', '13', '-', '-', '-', 'Linda_Hamilton', '*', '*', '-'], ['general', 'JJ', '*', 'O', 'bc/cnn/00/cnn_0003', '0', '14', '-', '-', '-', 'Linda_Hamilton', '*', '*', '-'], ['population', 'NN', '*)))))', 'O', 'bc/cnn/00/cnn_0003', '0', '15', 'population', '-', '2', 'Linda_Hamilton', '*)', '*', '-'], ['/.', '.', '*))', 'O', 'bc/cnn/00/cnn_0003', '0', '16', '-', '-', '-', 'Linda_Hamilton', '*', '*', '-'], [], ['A', 'DT', '(TOP(FRAG(NP*', 'O', 'bc/cnn/00/cnn_0000', '0', '0', '-', '-', '-', 'speaker1', '*', '*', '*', '(38'], ['much', 'RB', '(ADJP*', 'O', 'bc/cnn/00/cnn_0000', '0', '1', '-', '-', '-', 'speaker1', '*', '*', '*', '-'], ['better', 'JJR', '*))', 'O', 'bc/cnn/00/cnn_0000', '0', '2', '-', '-', '-', 'speaker1', '*', '*', '*', '-'], ['looking', 'VBG', '(VP*', 'O', 'bc/cnn/00/cnn_0000', '0', '3', 'look', '01', '1', 'speaker1', '(V*)', '*', '*', '-'], ['News', 'NNP', '(NP*', 'B-WORK_OF_ART', 'bc/cnn/00/cnn_0000', '0', '4', '-', '-', '-', 'speaker1', '(ARG1*', '*', '*', '-'], ['Night', 'NN', '*)', 'I-WORK_OF_ART', 'bc/cnn/00/cnn_0000', '0', '5', 'night', '-', '1', 'speaker1', '*)', '*', '*', '38)'], ['I', 'PRP', '(SBAR(S(NP*)', 'O', 'bc/cnn/00/cnn_0000', '0', '6', '-', '-', '-', 'speaker1', '*', '(ARG0*)', '*', '(51)'], ['might', 'MD', '(VP*', 'O', 'bc/cnn/00/cnn_0000', '0', '7', '-', '-', '-', 'speaker1', '*', '(ARGM-MOD*)', '*', '-'], ['add', 'VB', '(VP*', 'O', 'bc/cnn/00/cnn_0000', '0', '8', 'add', '02', '1', 'speaker1', '*', '(V*)', '*', '-'], ['as', 'IN', '(SBAR*', 'O', 'bc/cnn/00/cnn_0000', '0', '9', '-', '-', '-', 'speaker1', '*', '(ARGM-CAU*', '*', '-'], ['Paula', 'NNP', '(S(NP*', 'B-PERSON', 'bc/cnn/00/cnn_0000', '0', '10', '-', '-', '-', 'speaker1', '*', '*', '(ARG1*', '(133'], ['Zahn', 'NNP', '*)', 'I-PERSON', 'bc/cnn/00/cnn_0000', '0', '11', '-', '-', '-', 'speaker1', '*', '*', '*)', '133)'], ['sits', 'VBZ', '(VP*', 'O', 'bc/cnn/00/cnn_0000', '0', '12', 'sit', '01', '1', 'speaker1', '*', '*', '(V*)', '-'], ['in', 'IN', '(PP*', 'O', 'bc/cnn/00/cnn_0000', '0', '13', '-', '-', '-', 'speaker1', '*', '*', '(ARG2*', '-'], ['for', 'IN', '(PP*', 'O', 'bc/cnn/00/cnn_0000', '0', '14', '-', '-', '-', 'speaker1', '*', '*', '*', '-'], ['Anderson', 'NNP', '(NP*', 'B-PERSON', 'bc/cnn/00/cnn_0000', '0', '15', '-', '-', '-', 'speaker1', '*', '*', '*', '(71|(105)'], ['and', 'CC', '*', 'O', 'bc/cnn/00/cnn_0000', '0', '16', '-', '-', '-', 'speaker1', '*', '*', '*', '-'], ['Aaron', 'NNP', '*)))))))))))', 'B-PERSON', 'bc/cnn/00/cnn_0000', '0', '17', '-', '-', '-', 'speaker1', '*', '*)', '*)', '(124)|71)'], ['/.', '.', '*))', 'O', 'bc/cnn/00/cnn_0000', '0', '18', '-', '-', '-', 'speaker1', '*', '*', '*', '-'], [], ['They', 'PRP', '(TOP(S(NP*)', 'O', 'bc/cnn/00/cnn_0000', '0', '0', '-', '-', '-', 'speaker1', '(71)'], [\"'re\", 'VBP', '(VP*', 'O', 'bc/cnn/00/cnn_0000', '0', '1', 'be', '-', '1', 'speaker1', '-'], ['both', 'DT', '*', 'O', 'bc/cnn/00/cnn_0000', '0', '2', '-', '-', '-', 'speaker1', '-'], ['off', 'RB', '(ADVP*))', 'O', 'bc/cnn/00/cnn_0000', '0', '3', '-', '-', '-', 'speaker1', '-'], ['/-', '.', '*))', 'O', 'bc/cnn/00/cnn_0000', '0', '4', '-', '-', '-', 'speaker1', '-'], [], ['Look', 'VB', '(TOP(S(VP*', 'O', 'bc/cnn/00/cnn_0000', '0', '0', 'look', '-', '1', 'speaker1', '-'], ['at', 'IN', '(PP*', 'O', 'bc/cnn/00/cnn_0000', '0', '1', '-', '-', '-', 'speaker1', '-'], ['that', 'DT', '(NP*)))', 'O', 'bc/cnn/00/cnn_0000', '0', '2', '-', '-', '-', 'speaker1', '(133)'], ['/.', '.', '*))', 'O', 'bc/cnn/00/cnn_0000', '0', '3', '-', '-', '-', 'speaker1', '-']], 'test': [['Yes', 'UH', '(TOP(S(INTJ*)', 'O', 'bc/cnn/00/cnn_0003', '0', '0', '-', '-', '-', 'Linda_Hamilton', '*', '-'], ['they', 'PRP', '(NP*)', 'O', 'bc/cnn/00/cnn_0003', '0', '1', '-', '-', '-', 'Linda_Hamilton', '*', '(15)'], ['did', 'VBD', '(VP*)', 'O', 'bc/cnn/00/cnn_0003', '0', '2', 'do', '01', '-', 'Linda_Hamilton', '(V*)', '-'], ['/.', '.', '*))', 'O', 'bc/cnn/00/cnn_0003', '0', '3', '-', '-', '-', 'Linda_Hamilton', '*', '-'], [], ['and', 'CC', '(TOP(S*', 'O', 'bc/cnn/00/cnn_0003', '0', '0', '-', '-', '-', 'Linda_Hamilton', '(ARGM-DIS*)', '*', '-'], ['they', 'PRP', '(NP*)', 'O', 'bc/cnn/00/cnn_0003', '0', '1', '-', '-', '-', 'Linda_Hamilton', '(ARG1*)', '*', '(15)'], ['were', 'VBD', '(VP*', 'O', 'bc/cnn/00/cnn_0003', '0', '2', 'be', '01', '2', 'Linda_Hamilton', '(V*)', '*', '-'], ['not', 'RB', '*', 'O', 'bc/cnn/00/cnn_0003', '0', '3', '-', '-', '-', 'Linda_Hamilton', '(ARGM-NEG*)', '*', '-'], ['the', 'DT', '(NP(NP*', 'O', 'bc/cnn/00/cnn_0003', '0', '4', '-', '-', '-', 'Linda_Hamilton', '(ARG2*', '(ARG1*', '-'], ['first', 'JJ', '*', 'B-ORDINAL', 'bc/cnn/00/cnn_0003', '0', '5', '-', '-', '-', 'Linda_Hamilton', '*', '*', '-'], ['company', 'NN', '*)', 'O', 'bc/cnn/00/cnn_0003', '0', '6', 'company', '-', '1', 'Linda_Hamilton', '*', '*)', '-'], ['that', 'WDT', '(SBAR(WHNP*)', 'O', 'bc/cnn/00/cnn_0003', '0', '7', '-', '-', '-', 'Linda_Hamilton', '*', '(R-ARG1*)', '-'], ['approached', 'VBD', '(S(VP*', 'O', 'bc/cnn/00/cnn_0003', '0', '8', 'approach', '01', '2', 'Linda_Hamilton', '*', '(V*)', '-'], ['me', 'PRP', '(NP*))))))', 'O', 'bc/cnn/00/cnn_0003', '0', '9', '-', '-', '-', 'Linda_Hamilton', '*)', '(ARG2*)', '(76)'], ['/.', '.', '*))', 'O', 'bc/cnn/00/cnn_0003', '0', '10', '-', '-', '-', 'Linda_Hamilton', '*', '*', '-'], [], ['but', 'CC', '(TOP(S*', 'O', 'bc/cnn/00/cnn_0003', '0', '0', '-', '-', '-', 'Linda_Hamilton', '*', '*', '-'], ['I', 'PRP', '(S(NP*)', 'O', 'bc/cnn/00/cnn_0003', '0', '1', '-', '-', '-', 'Linda_Hamilton', '*', '(ARG0*)', '(76)'], ['am', 'VBP', '(VP*', 'O', 'bc/cnn/00/cnn_0003', '0', '2', 'be', '03', '-', 'Linda_Hamilton', '(V*)', '*', '-'], ['not', 'RB', '*', 'O', 'bc/cnn/00/cnn_0003', '0', '3', '-', '-', '-', 'Linda_Hamilton', '*', '(ARGM-NEG*)', '-'], ['selling', 'VBG', '(VP*', 'O', 'bc/cnn/00/cnn_0003', '0', '4', 'sell', '01', '1', 'Linda_Hamilton', '*', '(V*)', '-'], ['medicine', 'NN', '(NP*', 'O', 'bc/cnn/00/cnn_0003', '0', '5', 'medicine', '-', '1', 'Linda_Hamilton', '*', '(ARG1*', '-'], ['or', 'CC', '*', 'O', 'bc/cnn/00/cnn_0003', '0', '6', '-', '-', '-', 'Linda_Hamilton', '*', '*', '-'], ['pharmaceuticals', 'NNS', '*))))', 'O', 'bc/cnn/00/cnn_0003', '0', '7', '-', '-', '-', 'Linda_Hamilton', '*', '*)', '-'], ['/.', '.', '*))', 'O', 'bc/cnn/00/cnn_0003', '0', '8', '-', '-', '-', 'Linda_Hamilton', '*', '*', '-'], [], ['I', 'PRP', '(TOP(S(NP*)', 'O', 'bc/cnn/00/cnn_0003', '0', '0', '-', '-', '-', 'Linda_Hamilton', '(ARG1*)', '*', '*', '(76)'], [\"'m\", 'VBP', '(VP*', 'O', 'bc/cnn/00/cnn_0003', '0', '1', 'be', '01', '1', 'Linda_Hamilton', '(V*)', '*', '*', '-'], ['sort', 'RB', '(PP(ADVP*', 'O', 'bc/cnn/00/cnn_0003', '0', '2', '-', '-', '-', 'Linda_Hamilton', '(ARG2*', '*', '*', '-'], ['of', 'RB', '*)', 'O', 'bc/cnn/00/cnn_0003', '0', '3', '-', '-', '-', 'Linda_Hamilton', '*', '*', '*', '-'], ['about', 'IN', '*', 'O', 'bc/cnn/00/cnn_0003', '0', '4', '-', '-', '-', 'Linda_Hamilton', '*', '*', '*', '-'], ['selling', 'VBG', '(S(VP*', 'O', 'bc/cnn/00/cnn_0003', '0', '5', 'sell', '01', '2', 'Linda_Hamilton', '*', '(V*)', '*', '-'], ['a', 'DT', '(NP(NP*', 'O', 'bc/cnn/00/cnn_0003', '0', '6', '-', '-', '-', 'Linda_Hamilton', '*', '(ARG1*', '*', '-'], ['full', 'JJ', '(ADJP*', 'O', 'bc/cnn/00/cnn_0003', '0', '7', '-', '-', '-', 'Linda_Hamilton', '*', '*', '(ARG2*', '-'], ['body', 'NN', '*)', 'O', 'bc/cnn/00/cnn_0003', '0', '8', 'body', '-', '2', 'Linda_Hamilton', '*', '*', '*)', '-'], ['approach', 'NN', '*)', 'O', 'bc/cnn/00/cnn_0003', '0', '9', 'approach', '02', '3', 'Linda_Hamilton', '*', '*', '(V*)', '-'], ['to', 'IN', '(PP*', 'O', 'bc/cnn/00/cnn_0003', '0', '10', '-', '-', '-', 'Linda_Hamilton', '*', '*', '(ARG1*', '-'], ['wellness', 'NN', '(NP*)))))))', 'O', 'bc/cnn/00/cnn_0003', '0', '11', '-', '-', '-', 'Linda_Hamilton', '*)', '*)', '*)', '-'], ['/.', '.', '*))', 'O', 'bc/cnn/00/cnn_0003', '0', '12', '-', '-', '-', 'Linda_Hamilton', '*', '*', '*', '-'], [], ['Um', 'UH', '(TOP(S(INTJ*)', 'O', 'bc/cnn/00/cnn_0003', '0', '0', '-', '-', '-', 'Linda_Hamilton', '(ARGM-DIS*)', '*', '-'], ['there', 'EX', '(NP*)', 'O', 'bc/cnn/00/cnn_0003', '0', '1', '-', '-', '-', 'Linda_Hamilton', '*', '*', '-'], [\"'s\", 'VBZ', '(VP*', 'O', 'bc/cnn/00/cnn_0003', '0', '2', 'be', '02', '3', 'Linda_Hamilton', '(V*)', '*', '-'], ['a', 'DT', '(NP(NP*', 'O', 'bc/cnn/00/cnn_0003', '0', '3', '-', '-', '-', 'Linda_Hamilton', '(ARG1*', '*', '-'], ['big', 'JJ', '*', 'O', 'bc/cnn/00/cnn_0003', '0', '4', '-', '-', '-', 'Linda_Hamilton', '*', '*', '-'], ['gap', 'NN', '*)', 'O', 'bc/cnn/00/cnn_0003', '0', '5', 'gap', '-', '4', 'Linda_Hamilton', '*', '*', '-'], ['between', 'IN', '(PP*', 'O', 'bc/cnn/00/cnn_0003', '0', '6', '-', '-', '-', 'Linda_Hamilton', '*', '*', '-'], ['those', 'DT', '(NP(NP(NP*)', 'O', 'bc/cnn/00/cnn_0003', '0', '7', '-', '-', '-', 'Linda_Hamilton', '*', '(ARG1*)', '-'], ['that', 'WDT', '(SBAR(WHNP*)', 'O', 'bc/cnn/00/cnn_0003', '0', '8', '-', '-', '-', 'Linda_Hamilton', '*', '(R-ARG1*)', '-'], ['are', 'VBP', '(S(VP*', 'O', 'bc/cnn/00/cnn_0003', '0', '9', 'be', '01', '1', 'Linda_Hamilton', '*', '(V*)', '-'], ['mentally', 'RB', '(ADJP*', 'O', 'bc/cnn/00/cnn_0003', '0', '10', '-', '-', '-', 'Linda_Hamilton', '*', '(ARG2*', '-'], ['ill', 'JJ', '*)))))', 'O', 'bc/cnn/00/cnn_0003', '0', '11', '-', '-', '-', 'Linda_Hamilton', '*', '*)', '-'], ['and', 'CC', '*', 'O', 'bc/cnn/00/cnn_0003', '0', '12', '-', '-', '-', 'Linda_Hamilton', '*', '*', '-'], ['the', 'DT', '(NP*', 'O', 'bc/cnn/00/cnn_0003', '0', '13', '-', '-', '-', 'Linda_Hamilton', '*', '*', '-'], ['general', 'JJ', '*', 'O', 'bc/cnn/00/cnn_0003', '0', '14', '-', '-', '-', 'Linda_Hamilton', '*', '*', '-'], ['population', 'NN', '*)))))', 'O', 'bc/cnn/00/cnn_0003', '0', '15', 'population', '-', '2', 'Linda_Hamilton', '*)', '*', '-'], ['/.', '.', '*))', 'O', 'bc/cnn/00/cnn_0003', '0', '16', '-', '-', '-', 'Linda_Hamilton', '*', '*', '-'], [], ['A', 'DT', '(TOP(FRAG(NP*', 'O', 'bc/cnn/00/cnn_0000', '0', '0', '-', '-', '-', 'speaker1', '*', '*', '*', '(38'], ['much', 'RB', '(ADJP*', 'O', 'bc/cnn/00/cnn_0000', '0', '1', '-', '-', '-', 'speaker1', '*', '*', '*', '-'], ['better', 'JJR', '*))', 'O', 'bc/cnn/00/cnn_0000', '0', '2', '-', '-', '-', 'speaker1', '*', '*', '*', '-'], ['looking', 'VBG', '(VP*', 'O', 'bc/cnn/00/cnn_0000', '0', '3', 'look', '01', '1', 'speaker1', '(V*)', '*', '*', '-'], ['News', 'NNP', '(NP*', 'B-WORK_OF_ART', 'bc/cnn/00/cnn_0000', '0', '4', '-', '-', '-', 'speaker1', '(ARG1*', '*', '*', '-'], ['Night', 'NN', '*)', 'I-WORK_OF_ART', 'bc/cnn/00/cnn_0000', '0', '5', 'night', '-', '1', 'speaker1', '*)', '*', '*', '38)'], ['I', 'PRP', '(SBAR(S(NP*)', 'O', 'bc/cnn/00/cnn_0000', '0', '6', '-', '-', '-', 'speaker1', '*', '(ARG0*)', '*', '(51)'], ['might', 'MD', '(VP*', 'O', 'bc/cnn/00/cnn_0000', '0', '7', '-', '-', '-', 'speaker1', '*', '(ARGM-MOD*)', '*', '-'], ['add', 'VB', '(VP*', 'O', 'bc/cnn/00/cnn_0000', '0', '8', 'add', '02', '1', 'speaker1', '*', '(V*)', '*', '-'], ['as', 'IN', '(SBAR*', 'O', 'bc/cnn/00/cnn_0000', '0', '9', '-', '-', '-', 'speaker1', '*', '(ARGM-CAU*', '*', '-'], ['Paula', 'NNP', '(S(NP*', 'B-PERSON', 'bc/cnn/00/cnn_0000', '0', '10', '-', '-', '-', 'speaker1', '*', '*', '(ARG1*', '(133'], ['Zahn', 'NNP', '*)', 'I-PERSON', 'bc/cnn/00/cnn_0000', '0', '11', '-', '-', '-', 'speaker1', '*', '*', '*)', '133)'], ['sits', 'VBZ', '(VP*', 'O', 'bc/cnn/00/cnn_0000', '0', '12', 'sit', '01', '1', 'speaker1', '*', '*', '(V*)', '-'], ['in', 'IN', '(PP*', 'O', 'bc/cnn/00/cnn_0000', '0', '13', '-', '-', '-', 'speaker1', '*', '*', '(ARG2*', '-'], ['for', 'IN', '(PP*', 'O', 'bc/cnn/00/cnn_0000', '0', '14', '-', '-', '-', 'speaker1', '*', '*', '*', '-'], ['Anderson', 'NNP', '(NP*', 'B-PERSON', 'bc/cnn/00/cnn_0000', '0', '15', '-', '-', '-', 'speaker1', '*', '*', '*', '(71|(105)'], ['and', 'CC', '*', 'O', 'bc/cnn/00/cnn_0000', '0', '16', '-', '-', '-', 'speaker1', '*', '*', '*', '-'], ['Aaron', 'NNP', '*)))))))))))', 'B-PERSON', 'bc/cnn/00/cnn_0000', '0', '17', '-', '-', '-', 'speaker1', '*', '*)', '*)', '(124)|71)'], ['/.', '.', '*))', 'O', 'bc/cnn/00/cnn_0000', '0', '18', '-', '-', '-', 'speaker1', '*', '*', '*', '-'], [], ['They', 'PRP', '(TOP(S(NP*)', 'O', 'bc/cnn/00/cnn_0000', '0', '0', '-', '-', '-', 'speaker1', '(71)'], [\"'re\", 'VBP', '(VP*', 'O', 'bc/cnn/00/cnn_0000', '0', '1', 'be', '-', '1', 'speaker1', '-'], ['both', 'DT', '*', 'O', 'bc/cnn/00/cnn_0000', '0', '2', '-', '-', '-', 'speaker1', '-'], ['off', 'RB', '(ADVP*))', 'O', 'bc/cnn/00/cnn_0000', '0', '3', '-', '-', '-', 'speaker1', '-'], ['/-', '.', '*))', 'O', 'bc/cnn/00/cnn_0000', '0', '4', '-', '-', '-', 'speaker1', '-'], [], ['Look', 'VB', '(TOP(S(VP*', 'O', 'bc/cnn/00/cnn_0000', '0', '0', 'look', '-', '1', 'speaker1', '-'], ['at', 'IN', '(PP*', 'O', 'bc/cnn/00/cnn_0000', '0', '1', '-', '-', '-', 'speaker1', '-'], ['that', 'DT', '(NP*)))', 'O', 'bc/cnn/00/cnn_0000', '0', '2', '-', '-', '-', 'speaker1', '(133)'], ['/.', '.', '*))', 'O', 'bc/cnn/00/cnn_0000', '0', '3', '-', '-', '-', 'speaker1', '-']], 'dev': [['Yes', 'UH', '(TOP(S(INTJ*)', 'O', 'bc/cnn/00/cnn_0003', '0', '0', '-', '-', '-', 'Linda_Hamilton', '*', '-'], ['they', 'PRP', '(NP*)', 'O', 'bc/cnn/00/cnn_0003', '0', '1', '-', '-', '-', 'Linda_Hamilton', '*', '(15)'], ['did', 'VBD', '(VP*)', 'O', 'bc/cnn/00/cnn_0003', '0', '2', 'do', '01', '-', 'Linda_Hamilton', '(V*)', '-'], ['/.', '.', '*))', 'O', 'bc/cnn/00/cnn_0003', '0', '3', '-', '-', '-', 'Linda_Hamilton', '*', '-'], [], ['and', 'CC', '(TOP(S*', 'O', 'bc/cnn/00/cnn_0003', '0', '0', '-', '-', '-', 'Linda_Hamilton', '(ARGM-DIS*)', '*', '-'], ['they', 'PRP', '(NP*)', 'O', 'bc/cnn/00/cnn_0003', '0', '1', '-', '-', '-', 'Linda_Hamilton', '(ARG1*)', '*', '(15)'], ['were', 'VBD', '(VP*', 'O', 'bc/cnn/00/cnn_0003', '0', '2', 'be', '01', '2', 'Linda_Hamilton', '(V*)', '*', '-'], ['not', 'RB', '*', 'O', 'bc/cnn/00/cnn_0003', '0', '3', '-', '-', '-', 'Linda_Hamilton', '(ARGM-NEG*)', '*', '-'], ['the', 'DT', '(NP(NP*', 'O', 'bc/cnn/00/cnn_0003', '0', '4', '-', '-', '-', 'Linda_Hamilton', '(ARG2*', '(ARG1*', '-'], ['first', 'JJ', '*', 'B-ORDINAL', 'bc/cnn/00/cnn_0003', '0', '5', '-', '-', '-', 'Linda_Hamilton', '*', '*', '-'], ['company', 'NN', '*)', 'O', 'bc/cnn/00/cnn_0003', '0', '6', 'company', '-', '1', 'Linda_Hamilton', '*', '*)', '-'], ['that', 'WDT', '(SBAR(WHNP*)', 'O', 'bc/cnn/00/cnn_0003', '0', '7', '-', '-', '-', 'Linda_Hamilton', '*', '(R-ARG1*)', '-'], ['approached', 'VBD', '(S(VP*', 'O', 'bc/cnn/00/cnn_0003', '0', '8', 'approach', '01', '2', 'Linda_Hamilton', '*', '(V*)', '-'], ['me', 'PRP', '(NP*))))))', 'O', 'bc/cnn/00/cnn_0003', '0', '9', '-', '-', '-', 'Linda_Hamilton', '*)', '(ARG2*)', '(76)'], ['/.', '.', '*))', 'O', 'bc/cnn/00/cnn_0003', '0', '10', '-', '-', '-', 'Linda_Hamilton', '*', '*', '-'], [], ['but', 'CC', '(TOP(S*', 'O', 'bc/cnn/00/cnn_0003', '0', '0', '-', '-', '-', 'Linda_Hamilton', '*', '*', '-'], ['I', 'PRP', '(S(NP*)', 'O', 'bc/cnn/00/cnn_0003', '0', '1', '-', '-', '-', 'Linda_Hamilton', '*', '(ARG0*)', '(76)'], ['am', 'VBP', '(VP*', 'O', 'bc/cnn/00/cnn_0003', '0', '2', 'be', '03', '-', 'Linda_Hamilton', '(V*)', '*', '-'], ['not', 'RB', '*', 'O', 'bc/cnn/00/cnn_0003', '0', '3', '-', '-', '-', 'Linda_Hamilton', '*', '(ARGM-NEG*)', '-'], ['selling', 'VBG', '(VP*', 'O', 'bc/cnn/00/cnn_0003', '0', '4', 'sell', '01', '1', 'Linda_Hamilton', '*', '(V*)', '-'], ['medicine', 'NN', '(NP*', 'O', 'bc/cnn/00/cnn_0003', '0', '5', 'medicine', '-', '1', 'Linda_Hamilton', '*', '(ARG1*', '-'], ['or', 'CC', '*', 'O', 'bc/cnn/00/cnn_0003', '0', '6', '-', '-', '-', 'Linda_Hamilton', '*', '*', '-'], ['pharmaceuticals', 'NNS', '*))))', 'O', 'bc/cnn/00/cnn_0003', '0', '7', '-', '-', '-', 'Linda_Hamilton', '*', '*)', '-'], ['/.', '.', '*))', 'O', 'bc/cnn/00/cnn_0003', '0', '8', '-', '-', '-', 'Linda_Hamilton', '*', '*', '-'], [], ['I', 'PRP', '(TOP(S(NP*)', 'O', 'bc/cnn/00/cnn_0003', '0', '0', '-', '-', '-', 'Linda_Hamilton', '(ARG1*)', '*', '*', '(76)'], [\"'m\", 'VBP', '(VP*', 'O', 'bc/cnn/00/cnn_0003', '0', '1', 'be', '01', '1', 'Linda_Hamilton', '(V*)', '*', '*', '-'], ['sort', 'RB', '(PP(ADVP*', 'O', 'bc/cnn/00/cnn_0003', '0', '2', '-', '-', '-', 'Linda_Hamilton', '(ARG2*', '*', '*', '-'], ['of', 'RB', '*)', 'O', 'bc/cnn/00/cnn_0003', '0', '3', '-', '-', '-', 'Linda_Hamilton', '*', '*', '*', '-'], ['about', 'IN', '*', 'O', 'bc/cnn/00/cnn_0003', '0', '4', '-', '-', '-', 'Linda_Hamilton', '*', '*', '*', '-'], ['selling', 'VBG', '(S(VP*', 'O', 'bc/cnn/00/cnn_0003', '0', '5', 'sell', '01', '2', 'Linda_Hamilton', '*', '(V*)', '*', '-'], ['a', 'DT', '(NP(NP*', 'O', 'bc/cnn/00/cnn_0003', '0', '6', '-', '-', '-', 'Linda_Hamilton', '*', '(ARG1*', '*', '-'], ['full', 'JJ', '(ADJP*', 'O', 'bc/cnn/00/cnn_0003', '0', '7', '-', '-', '-', 'Linda_Hamilton', '*', '*', '(ARG2*', '-'], ['body', 'NN', '*)', 'O', 'bc/cnn/00/cnn_0003', '0', '8', 'body', '-', '2', 'Linda_Hamilton', '*', '*', '*)', '-'], ['approach', 'NN', '*)', 'O', 'bc/cnn/00/cnn_0003', '0', '9', 'approach', '02', '3', 'Linda_Hamilton', '*', '*', '(V*)', '-'], ['to', 'IN', '(PP*', 'O', 'bc/cnn/00/cnn_0003', '0', '10', '-', '-', '-', 'Linda_Hamilton', '*', '*', '(ARG1*', '-'], ['wellness', 'NN', '(NP*)))))))', 'O', 'bc/cnn/00/cnn_0003', '0', '11', '-', '-', '-', 'Linda_Hamilton', '*)', '*)', '*)', '-'], ['/.', '.', '*))', 'O', 'bc/cnn/00/cnn_0003', '0', '12', '-', '-', '-', 'Linda_Hamilton', '*', '*', '*', '-'], [], ['Um', 'UH', '(TOP(S(INTJ*)', 'O', 'bc/cnn/00/cnn_0003', '0', '0', '-', '-', '-', 'Linda_Hamilton', '(ARGM-DIS*)', '*', '-'], ['there', 'EX', '(NP*)', 'O', 'bc/cnn/00/cnn_0003', '0', '1', '-', '-', '-', 'Linda_Hamilton', '*', '*', '-'], [\"'s\", 'VBZ', '(VP*', 'O', 'bc/cnn/00/cnn_0003', '0', '2', 'be', '02', '3', 'Linda_Hamilton', '(V*)', '*', '-'], ['a', 'DT', '(NP(NP*', 'O', 'bc/cnn/00/cnn_0003', '0', '3', '-', '-', '-', 'Linda_Hamilton', '(ARG1*', '*', '-'], ['big', 'JJ', '*', 'O', 'bc/cnn/00/cnn_0003', '0', '4', '-', '-', '-', 'Linda_Hamilton', '*', '*', '-'], ['gap', 'NN', '*)', 'O', 'bc/cnn/00/cnn_0003', '0', '5', 'gap', '-', '4', 'Linda_Hamilton', '*', '*', '-'], ['between', 'IN', '(PP*', 'O', 'bc/cnn/00/cnn_0003', '0', '6', '-', '-', '-', 'Linda_Hamilton', '*', '*', '-'], ['those', 'DT', '(NP(NP(NP*)', 'O', 'bc/cnn/00/cnn_0003', '0', '7', '-', '-', '-', 'Linda_Hamilton', '*', '(ARG1*)', '-'], ['that', 'WDT', '(SBAR(WHNP*)', 'O', 'bc/cnn/00/cnn_0003', '0', '8', '-', '-', '-', 'Linda_Hamilton', '*', '(R-ARG1*)', '-'], ['are', 'VBP', '(S(VP*', 'O', 'bc/cnn/00/cnn_0003', '0', '9', 'be', '01', '1', 'Linda_Hamilton', '*', '(V*)', '-'], ['mentally', 'RB', '(ADJP*', 'O', 'bc/cnn/00/cnn_0003', '0', '10', '-', '-', '-', 'Linda_Hamilton', '*', '(ARG2*', '-'], ['ill', 'JJ', '*)))))', 'O', 'bc/cnn/00/cnn_0003', '0', '11', '-', '-', '-', 'Linda_Hamilton', '*', '*)', '-'], ['and', 'CC', '*', 'O', 'bc/cnn/00/cnn_0003', '0', '12', '-', '-', '-', 'Linda_Hamilton', '*', '*', '-'], ['the', 'DT', '(NP*', 'O', 'bc/cnn/00/cnn_0003', '0', '13', '-', '-', '-', 'Linda_Hamilton', '*', '*', '-'], ['general', 'JJ', '*', 'O', 'bc/cnn/00/cnn_0003', '0', '14', '-', '-', '-', 'Linda_Hamilton', '*', '*', '-'], ['population', 'NN', '*)))))', 'O', 'bc/cnn/00/cnn_0003', '0', '15', 'population', '-', '2', 'Linda_Hamilton', '*)', '*', '-'], ['/.', '.', '*))', 'O', 'bc/cnn/00/cnn_0003', '0', '16', '-', '-', '-', 'Linda_Hamilton', '*', '*', '-'], [], ['A', 'DT', '(TOP(FRAG(NP*', 'O', 'bc/cnn/00/cnn_0000', '0', '0', '-', '-', '-', 'speaker1', '*', '*', '*', '(38'], ['much', 'RB', '(ADJP*', 'O', 'bc/cnn/00/cnn_0000', '0', '1', '-', '-', '-', 'speaker1', '*', '*', '*', '-'], ['better', 'JJR', '*))', 'O', 'bc/cnn/00/cnn_0000', '0', '2', '-', '-', '-', 'speaker1', '*', '*', '*', '-'], ['looking', 'VBG', '(VP*', 'O', 'bc/cnn/00/cnn_0000', '0', '3', 'look', '01', '1', 'speaker1', '(V*)', '*', '*', '-'], ['News', 'NNP', '(NP*', 'B-WORK_OF_ART', 'bc/cnn/00/cnn_0000', '0', '4', '-', '-', '-', 'speaker1', '(ARG1*', '*', '*', '-'], ['Night', 'NN', '*)', 'I-WORK_OF_ART', 'bc/cnn/00/cnn_0000', '0', '5', 'night', '-', '1', 'speaker1', '*)', '*', '*', '38)'], ['I', 'PRP', '(SBAR(S(NP*)', 'O', 'bc/cnn/00/cnn_0000', '0', '6', '-', '-', '-', 'speaker1', '*', '(ARG0*)', '*', '(51)'], ['might', 'MD', '(VP*', 'O', 'bc/cnn/00/cnn_0000', '0', '7', '-', '-', '-', 'speaker1', '*', '(ARGM-MOD*)', '*', '-'], ['add', 'VB', '(VP*', 'O', 'bc/cnn/00/cnn_0000', '0', '8', 'add', '02', '1', 'speaker1', '*', '(V*)', '*', '-'], ['as', 'IN', '(SBAR*', 'O', 'bc/cnn/00/cnn_0000', '0', '9', '-', '-', '-', 'speaker1', '*', '(ARGM-CAU*', '*', '-'], ['Paula', 'NNP', '(S(NP*', 'B-PERSON', 'bc/cnn/00/cnn_0000', '0', '10', '-', '-', '-', 'speaker1', '*', '*', '(ARG1*', '(133'], ['Zahn', 'NNP', '*)', 'I-PERSON', 'bc/cnn/00/cnn_0000', '0', '11', '-', '-', '-', 'speaker1', '*', '*', '*)', '133)'], ['sits', 'VBZ', '(VP*', 'O', 'bc/cnn/00/cnn_0000', '0', '12', 'sit', '01', '1', 'speaker1', '*', '*', '(V*)', '-'], ['in', 'IN', '(PP*', 'O', 'bc/cnn/00/cnn_0000', '0', '13', '-', '-', '-', 'speaker1', '*', '*', '(ARG2*', '-'], ['for', 'IN', '(PP*', 'O', 'bc/cnn/00/cnn_0000', '0', '14', '-', '-', '-', 'speaker1', '*', '*', '*', '-'], ['Anderson', 'NNP', '(NP*', 'B-PERSON', 'bc/cnn/00/cnn_0000', '0', '15', '-', '-', '-', 'speaker1', '*', '*', '*', '(71|(105)'], ['and', 'CC', '*', 'O', 'bc/cnn/00/cnn_0000', '0', '16', '-', '-', '-', 'speaker1', '*', '*', '*', '-'], ['Aaron', 'NNP', '*)))))))))))', 'B-PERSON', 'bc/cnn/00/cnn_0000', '0', '17', '-', '-', '-', 'speaker1', '*', '*)', '*)', '(124)|71)'], ['/.', '.', '*))', 'O', 'bc/cnn/00/cnn_0000', '0', '18', '-', '-', '-', 'speaker1', '*', '*', '*', '-'], [], ['They', 'PRP', '(TOP(S(NP*)', 'O', 'bc/cnn/00/cnn_0000', '0', '0', '-', '-', '-', 'speaker1', '(71)'], [\"'re\", 'VBP', '(VP*', 'O', 'bc/cnn/00/cnn_0000', '0', '1', 'be', '-', '1', 'speaker1', '-'], ['both', 'DT', '*', 'O', 'bc/cnn/00/cnn_0000', '0', '2', '-', '-', '-', 'speaker1', '-'], ['off', 'RB', '(ADVP*))', 'O', 'bc/cnn/00/cnn_0000', '0', '3', '-', '-', '-', 'speaker1', '-'], ['/-', '.', '*))', 'O', 'bc/cnn/00/cnn_0000', '0', '4', '-', '-', '-', 'speaker1', '-'], [], ['Look', 'VB', '(TOP(S(VP*', 'O', 'bc/cnn/00/cnn_0000', '0', '0', 'look', '-', '1', 'speaker1', '-'], ['at', 'IN', '(PP*', 'O', 'bc/cnn/00/cnn_0000', '0', '1', '-', '-', '-', 'speaker1', '-'], ['that', 'DT', '(NP*)))', 'O', 'bc/cnn/00/cnn_0000', '0', '2', '-', '-', '-', 'speaker1', '(133)'], ['/.', '.', '*))', 'O', 'bc/cnn/00/cnn_0000', '0', '3', '-', '-', '-', 'speaker1', '-']]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[main.py:96 - convert_ground_truth() ] (None,)\n",
      "[main.py:97 - convert_ground_truth() ] {}\n",
      "[main.py:108 - convert_ground_truth() ] Returning ground truths for the test input file :\n",
      "[main.py:109 - convert_ground_truth() ] [[None, None, 'Yes', 'O'], [None, None, 'they', 'O'], [None, None, 'did', 'O'], [None, None, '/.', 'O'], [None, None, 'and', 'O'], [None, None, 'they', 'O'], [None, None, 'were', 'O'], [None, None, 'not', 'O'], [None, None, 'the', 'O'], [None, None, 'first', 'B-ORDINAL'], [None, None, 'company', 'O'], [None, None, 'that', 'O'], [None, None, 'approached', 'O'], [None, None, 'me', 'O'], [None, None, '/.', 'O'], [None, None, 'but', 'O'], [None, None, 'I', 'O'], [None, None, 'am', 'O'], [None, None, 'not', 'O'], [None, None, 'selling', 'O'], [None, None, 'medicine', 'O'], [None, None, 'or', 'O'], [None, None, 'pharmaceuticals', 'O'], [None, None, '/.', 'O'], [None, None, 'I', 'O'], [None, None, \"'m\", 'O'], [None, None, 'sort', 'O'], [None, None, 'of', 'O'], [None, None, 'about', 'O'], [None, None, 'selling', 'O'], [None, None, 'a', 'O'], [None, None, 'full', 'O'], [None, None, 'body', 'O'], [None, None, 'approach', 'O'], [None, None, 'to', 'O'], [None, None, 'wellness', 'O'], [None, None, '/.', 'O'], [None, None, 'Um', 'O'], [None, None, 'there', 'O'], [None, None, \"'s\", 'O'], [None, None, 'a', 'O'], [None, None, 'big', 'O'], [None, None, 'gap', 'O'], [None, None, 'between', 'O'], [None, None, 'those', 'O'], [None, None, 'that', 'O'], [None, None, 'are', 'O'], [None, None, 'mentally', 'O'], [None, None, 'ill', 'O'], [None, None, 'and', 'O'], [None, None, 'the', 'O'], [None, None, 'general', 'O'], [None, None, 'population', 'O'], [None, None, '/.', 'O'], [None, None, 'A', 'O'], [None, None, 'much', 'O'], [None, None, 'better', 'O'], [None, None, 'looking', 'O'], [None, None, 'News', 'B-WORK_OF_ART'], [None, None, 'Night', 'I-WORK_OF_ART'], [None, None, 'I', 'O'], [None, None, 'might', 'O'], [None, None, 'add', 'O'], [None, None, 'as', 'O'], [None, None, 'Paula', 'B-PERSON'], [None, None, 'Zahn', 'I-PERSON'], [None, None, 'sits', 'O'], [None, None, 'in', 'O'], [None, None, 'for', 'O'], [None, None, 'Anderson', 'B-PERSON'], [None, None, 'and', 'O'], [None, None, 'Aaron', 'B-PERSON'], [None, None, '/.', 'O'], [None, None, 'They', 'O'], [None, None, \"'re\", 'O'], [None, None, 'both', 'O'], [None, None, 'off', 'O'], [None, None, '/-', 'O'], [None, None, 'Look', 'O'], [None, None, 'at', 'O'], [None, None, 'that', 'O'], [None, None, '/.', 'O']]\n"
     ]
    }
   ],
   "source": [
    "groundTruth = deen.convert_ground_truth(data, None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the model\n",
    "- Description\n",
    "    * Trains he model on the parsed data\n",
    "    * Calls the internal save_model method to save the trained model for predictions\n",
    "- Returns\n",
    "    * Not Applicable\n",
    "- Arguments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    "    <thead>\n",
    "        <tr>\n",
    "            <th>Type</th>\n",
    "            <th>Name</th>\n",
    "            <th>Default</th>\n",
    "            <th>Purpose</th>\n",
    "            <th>Required</th>\n",
    "        </tr>\n",
    "    </thead>\n",
    "    <tbody>\n",
    "        <tr>\n",
    "            <td>Standard</td>\n",
    "            <td>data</td>\n",
    "            <td>-</td>\n",
    "            <td>Parsed input data in the format returned by read_dataset method</td>\n",
    "            <td>✔</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>args</td>\n",
    "            <td>N/A</td>\n",
    "            <td>None</td>\n",
    "            <td>N/A</td>\n",
    "            <td>✖</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td rowspan=\"22\">kwargs</td>\n",
    "            <td>parsedDumpPath</td>\n",
    "            <td>../dev/parsedDataDump.pkl</td>\n",
    "            <td>Location of the parsed input data-files in the pickled format</td>\n",
    "            <td>✖</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>vocabPath</td>\n",
    "            <td>../dev/vocab.txt</td>\n",
    "            <td>Location of the parsed vocab</td>\n",
    "            <td>✖</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>elmoOptionsFile</td>\n",
    "            <td>../resources/elmo/elmo_2x4096_512_2048cnn_2xhighway_5.5B_options.json</td>\n",
    "            <td>ELMo model options parameters file</td>\n",
    "            <td>✔</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>elmoWeightFile</td>\n",
    "            <td>../resources/elmo/elmo_2x4096_512_2048cnn_2xhighway_5.5B_weights.hdf5</td>\n",
    "            <td>ELMo model weights file</td>\n",
    "            <td>✔</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>wordEmbeddingSize</td>\n",
    "            <td>50</td>\n",
    "            <td>Set the ELMo word embedding size for the model</td>\n",
    "            <td>✖</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>charEmbeddingSize</td>\n",
    "            <td>16</td>\n",
    "            <td>Set the ELMo character embedding size for the model</td>\n",
    "            <td>✖</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>LSTMStateSize</td>\n",
    "            <td>200</td>\n",
    "            <td>State size of the Multi-LSTM layers</td>\n",
    "            <td>✖</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>filterNum</td>\n",
    "            <td>128</td>\n",
    "            <td>Filter area size</td>\n",
    "            <td>✖</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>filterSize</td>\n",
    "            <td>3</td>\n",
    "            <td>Number of filters in the model</td>\n",
    "            <td>✖</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>learningRate</td>\n",
    "            <td>0.015</td>\n",
    "            <td>Model learning rate</td>\n",
    "            <td>✖</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>dropoutRate</td>\n",
    "            <td>0.5</td>\n",
    "            <td>Model dropout rate</td>\n",
    "            <td>✖</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>epochWidth</td>\n",
    "            <td>16</td>\n",
    "            <td>Batch size within each epoch</td>\n",
    "            <td>✖</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>maxEpoch</td>\n",
    "            <td>100</td>\n",
    "            <td>Number of epoch to run for training</td>\n",
    "            <td>✖</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>checkpointPath</td>\n",
    "            <td>../results/checkpoints</td>\n",
    "            <td>Location to save intermediate checkpoints</td>\n",
    "            <td>✖</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>bestCheckpointPath</td>\n",
    "            <td>../results/checkpoints/best</td>\n",
    "            <td>Location to save the best F1 returning</td>\n",
    "            <td>✖</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>trainWordsPath</td>\n",
    "            <td>../dev/train.word.vocab</td>\n",
    "            <td>Location to save the intermediate vocabulary words from the training set</td>\n",
    "            <td>✖</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>trainCharPath</td>\n",
    "            <td>../dev/train.char.vocab</td>\n",
    "            <td>Location to save the intermediate vocabulary characters from the training set</td>\n",
    "            <td>✖</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>gloveEmbedPath</td>\n",
    "            <td>../resources/glove/glove.6B.50d.txt</td>\n",
    "            <td>Location fo the glove embedding file</td>\n",
    "            <td>✔</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>fetchPredictData</td>\n",
    "            <td>False</td>\n",
    "            <td>Flag to toggle behaviour of the internal data_converter method</td>\n",
    "            <td>✔</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>maxWordLength</td>\n",
    "            <td>30</td>\n",
    "            <td>Set maximal word length for the model</td>\n",
    "            <td>✖</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>wordPosition</td>\n",
    "            <td>0</td>\n",
    "            <td>Column number with the mention word</td>\n",
    "            <td>✖</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>tagPosition</td>\n",
    "            <td>3</td>\n",
    "            <td>Column number with the entity tag</td>\n",
    "            <td>✖</td>\n",
    "        </tr>\n",
    "    </tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[main.py:231 - train() ] Loading elmo!\n",
      "[main.py:236 - train() ] Loading model!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From c:\\users\\sarve\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[deprecation.py:323 - new_func() ] From c:\\users\\sarve\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "[smart_open_lib.py:385 - smart_open() ] this function is deprecated, use smart_open.open instead\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From c:\\users\\sarve\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\ops\\lookup_ops.py:1137: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[deprecation.py:323 - new_func() ] From c:\\users\\sarve\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\ops\\lookup_ops.py:1137: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From ..\\model\\Elmo.py:138: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[deprecation.py:506 - new_func() ] From ..\\model\\Elmo.py:138: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From ..\\model\\bilm\\model.py:412: calling squeeze (from tensorflow.python.ops.array_ops) with squeeze_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use the `axis` argument instead\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[deprecation.py:506 - new_func() ] From ..\\model\\bilm\\model.py:412: calling squeeze (from tensorflow.python.ops.array_ops) with squeeze_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use the `axis` argument instead\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USING SKIP CONNECTIONS\n",
      "From ..\\model\\bilm\\model.py:552: LSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[deprecation.py:323 - new_func() ] From ..\\model\\bilm\\model.py:552: LSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From ..\\model\\bilm\\model.py:597: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[deprecation.py:323 - new_func() ] From ..\\model\\bilm\\model.py:597: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From c:\\users\\sarve\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\ops\\rnn.py:626: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[deprecation.py:323 - new_func() ] From c:\\users\\sarve\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\ops\\rnn.py:626: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From ..\\model\\Elmo.py:181: GRUCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.GRUCell, and will be replaced by that in Tensorflow 2.0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[deprecation.py:323 - new_func() ] From ..\\model\\Elmo.py:181: GRUCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.GRUCell, and will be replaced by that in Tensorflow 2.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From c:\\users\\sarve\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\contrib\\rnn\\python\\ops\\rnn.py:233: bidirectional_dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.Bidirectional(keras.layers.RNN(cell))`, which is equivalent to this API\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[deprecation.py:323 - new_func() ] From c:\\users\\sarve\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\contrib\\rnn\\python\\ops\\rnn.py:233: bidirectional_dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.Bidirectional(keras.layers.RNN(cell))`, which is equivalent to this API\n",
      "[main.py:265 - train() ] Start training...\n",
      "[main.py:266 - train() ] Train size = 7\n",
      "[main.py:267 - train() ] Val size = 7\n",
      "[main.py:268 - train() ] Test size = 7\n",
      "[main.py:269 - train() ] Num classes = 6\n",
      "[main.py:274 - train() ] Epoch = 5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From c:\\users\\sarve\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\training\\saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[deprecation.py:323 - new_func() ] From c:\\users\\sarve\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\training\\saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restoring parameters from ../results/checkpoints\\model.ckpt-1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[saver.py:1270 - restore() ] Restoring parameters from ../results/checkpoints\\model.ckpt-1\n",
      "[main.py:306 - train() ] epoch: 1, size: 7/7, step_loss: 86.379494, epoch_loss: 86.379494\n",
      "[main.py:317 - train() ] ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ORDINAL', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-WORK_OF_ART', 'I-WORK_OF_ART', 'O', 'O', 'O', 'O', 'B-PERSON', 'I-PERSON', 'O', 'O', 'O', 'B-PERSON', 'O', 'B-PERSON', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "[main.py:318 - train() ] ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "[main.py:322 - train() ] Epoch: 1, val_p: 0.000000, val_r: 0.000000, val_f1: 0.000000\n",
      "[main.py:306 - train() ] epoch: 2, size: 7/7, step_loss: 44.208389, epoch_loss: 44.208389\n",
      "[main.py:317 - train() ] ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ORDINAL', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-WORK_OF_ART', 'I-WORK_OF_ART', 'O', 'O', 'O', 'O', 'B-PERSON', 'I-PERSON', 'O', 'O', 'O', 'B-PERSON', 'O', 'B-PERSON', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "[main.py:318 - train() ] ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "[main.py:322 - train() ] Epoch: 2, val_p: 0.000000, val_r: 0.000000, val_f1: 0.000000\n",
      "[main.py:306 - train() ] epoch: 3, size: 7/7, step_loss: 45.539639, epoch_loss: 45.539639\n",
      "[main.py:317 - train() ] ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ORDINAL', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-WORK_OF_ART', 'I-WORK_OF_ART', 'O', 'O', 'O', 'O', 'B-PERSON', 'I-PERSON', 'O', 'O', 'O', 'B-PERSON', 'O', 'B-PERSON', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "[main.py:318 - train() ] ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "[main.py:322 - train() ] Epoch: 3, val_p: 0.000000, val_r: 0.000000, val_f1: 0.000000\n",
      "[main.py:306 - train() ] epoch: 4, size: 7/7, step_loss: 40.980080, epoch_loss: 40.980080\n",
      "[main.py:317 - train() ] ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ORDINAL', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-WORK_OF_ART', 'I-WORK_OF_ART', 'O', 'O', 'O', 'O', 'B-PERSON', 'I-PERSON', 'O', 'O', 'O', 'B-PERSON', 'O', 'B-PERSON', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "[main.py:318 - train() ] ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PERSON', 'B-PERSON', 'B-PERSON', 'B-PERSON', 'B-PERSON', 'O', 'O', 'O', 'O', 'O']\n",
      "[main.py:322 - train() ] Epoch: 4, val_p: 40.000000, val_r: 40.000000, val_f1: 40.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../results/checkpoints/best\\best.ckpt-4 is not in all_model_checkpoint_paths. Manually adding it.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[checkpoint_management.py:95 - generate_checkpoint_state_proto() ] ../results/checkpoints/best\\best.ckpt-4 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "[main.py:306 - train() ] epoch: 5, size: 7/7, step_loss: 30.509827, epoch_loss: 30.509827\n",
      "[main.py:317 - train() ] ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ORDINAL', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-WORK_OF_ART', 'I-WORK_OF_ART', 'O', 'O', 'O', 'O', 'B-PERSON', 'I-PERSON', 'O', 'O', 'O', 'B-PERSON', 'O', 'B-PERSON', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "[main.py:318 - train() ] ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PERSON', 'B-PERSON', 'B-PERSON', 'B-PERSON', 'B-PERSON', 'B-PERSON', 'B-PERSON', 'B-PERSON', 'B-PERSON', 'B-PERSON', 'B-PERSON', 'B-PERSON', 'B-PERSON', 'B-PERSON', 'O', 'O', 'O', 'O', 'O']\n",
      "[main.py:322 - train() ] Epoch: 5, val_p: 14.285714, val_r: 40.000000, val_f1: 21.052632\n",
      "[main.py:332 - train() ] Training done! ... Saving trained model\n"
     ]
    }
   ],
   "source": [
    "model, sess, saver = deen.train(data, None, maxEpoch=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating predictions\n",
    "- Description\n",
    "    * Parses and converts the input sentence provided in a file for predicting the NER tags\n",
    "    * Calls the internal load_model method to load the trained model for predictions\n",
    "- Returns\n",
    "    * \\[tuple,...\\], i.e. list of tuples.\n",
    "    * Each tuple is (start index, span, mention text, mention type)\n",
    "    * Where:\n",
    "         - start index: int, the index of the first character of the mention span. None if not applicable.\n",
    "         - span: int, the length of the mention. None if not applicable.\n",
    "         - mention text: str, the actual text that was identified as a named entity. Required.\n",
    "         - mention type: str, the entity/mention type. None if not applicable.\n",
    "\n",
    "         `NOTE: len(predictions) should equal len(data) AND the ordering should not change [important for evaluation. See note in evaluate() about parallel arrays.]`\n",
    "- Arguments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    "    <thead>\n",
    "        <tr>\n",
    "            <th>Type</th>\n",
    "            <th>Name</th>\n",
    "            <th>Default</th>\n",
    "            <th>Purpose</th>\n",
    "            <th>Required</th>\n",
    "        </tr>\n",
    "    </thead>\n",
    "    <tbody>\n",
    "        <tr>\n",
    "            <td>Standard</td>\n",
    "            <td>data</td>\n",
    "            <td>-</td>\n",
    "            <td>The file location with the input text in the common format for prediction</td>\n",
    "            <td>✔</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>args</td>\n",
    "            <td>N/A</td>\n",
    "            <td>None</td>\n",
    "            <td>N/A</td>\n",
    "            <td>✖</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td rowspan=\"11\">kwargs</td>\n",
    "            <td>model</td>\n",
    "            <td>N/A</td>\n",
    "            <td>ElmoModel instance to hold the loaded model into</td>\n",
    "            <td>✔</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>sess</td>\n",
    "            <td>N/A</td>\n",
    "            <td>Tensorflow.Session instance used to maintain the same session used to train</td>\n",
    "            <td>✔</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>saver</td>\n",
    "            <td>N/A</td>\n",
    "            <td>Tensorflow.train.saver instance used to load the trained model</td>\n",
    "            <td>✔</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>trainedData</td>\n",
    "            <td>N/A</td>\n",
    "            <td>Parsed trained data</td>\n",
    "            <td>✔</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>fileHasHeaders</td>\n",
    "            <td>True</td>\n",
    "            <td>Flag to check if input file has headers</td>\n",
    "            <td>✖</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>parsedDumpPath</td>\n",
    "            <td>../dev/parsedDataDump.pkl</td>\n",
    "            <td>Location of the parsed input data-files in the pickled format</td>\n",
    "            <td>✖</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>bestCheckpointPath</td>\n",
    "            <td>../results/checkpoints/best</td>\n",
    "            <td>Location to save the best F1 returning</td>\n",
    "            <td>✖</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>epochWidth</td>\n",
    "            <td>16</td>\n",
    "            <td>Batch size within each epoch</td>\n",
    "            <td>✖</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>writePredsToFile</td>\n",
    "            <td>True</td>\n",
    "            <td>Flag to enable writing predictions to file</td>\n",
    "            <td>✖</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>predsPath</td>\n",
    "            <td>../results/predictions.txt</td>\n",
    "            <td>Location where to write predictions into</td>\n",
    "            <td>✖</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>writeInputToFile</td>\n",
    "            <td>False</td>\n",
    "            <td>Flag to toggle behaviour of the internal data_converter method</td>\n",
    "            <td>✔</td>\n",
    "        </tr>\n",
    "    </tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[main.py:368 - predict() ] Invoked predict method\n",
      "[main.py:369 - predict() ] With parameters : \n",
      "[main.py:370 - predict() ] ../data/sample/ner_test_input.txt\n",
      "[main.py:371 - predict() ] (None,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[main.py:372 - predict() ] {'writeInputToFile': False, 'model': <model.Elmo.ElmoModel object at 0x000001F265323630>, 'sess': <tensorflow.python.client.session.Session object at 0x000001F20D60AE10>, 'saver': <tensorflow.python.training.saver.Saver object at 0x000001F20CABD978>, 'trainedData': [['Yes', 'UH', '(TOP(S(INTJ*)', 'O', 'bc/cnn/00/cnn_0003', '0', '0', '-', '-', '-', 'Linda_Hamilton', '*', '-'], ['they', 'PRP', '(NP*)', 'O', 'bc/cnn/00/cnn_0003', '0', '1', '-', '-', '-', 'Linda_Hamilton', '*', '(15)'], ['did', 'VBD', '(VP*)', 'O', 'bc/cnn/00/cnn_0003', '0', '2', 'do', '01', '-', 'Linda_Hamilton', '(V*)', '-'], ['/.', '.', '*))', 'O', 'bc/cnn/00/cnn_0003', '0', '3', '-', '-', '-', 'Linda_Hamilton', '*', '-'], [], ['and', 'CC', '(TOP(S*', 'O', 'bc/cnn/00/cnn_0003', '0', '0', '-', '-', '-', 'Linda_Hamilton', '(ARGM-DIS*)', '*', '-'], ['they', 'PRP', '(NP*)', 'O', 'bc/cnn/00/cnn_0003', '0', '1', '-', '-', '-', 'Linda_Hamilton', '(ARG1*)', '*', '(15)'], ['were', 'VBD', '(VP*', 'O', 'bc/cnn/00/cnn_0003', '0', '2', 'be', '01', '2', 'Linda_Hamilton', '(V*)', '*', '-'], ['not', 'RB', '*', 'O', 'bc/cnn/00/cnn_0003', '0', '3', '-', '-', '-', 'Linda_Hamilton', '(ARGM-NEG*)', '*', '-'], ['the', 'DT', '(NP(NP*', 'O', 'bc/cnn/00/cnn_0003', '0', '4', '-', '-', '-', 'Linda_Hamilton', '(ARG2*', '(ARG1*', '-'], ['first', 'JJ', '*', 'B-ORDINAL', 'bc/cnn/00/cnn_0003', '0', '5', '-', '-', '-', 'Linda_Hamilton', '*', '*', '-'], ['company', 'NN', '*)', 'O', 'bc/cnn/00/cnn_0003', '0', '6', 'company', '-', '1', 'Linda_Hamilton', '*', '*)', '-'], ['that', 'WDT', '(SBAR(WHNP*)', 'O', 'bc/cnn/00/cnn_0003', '0', '7', '-', '-', '-', 'Linda_Hamilton', '*', '(R-ARG1*)', '-'], ['approached', 'VBD', '(S(VP*', 'O', 'bc/cnn/00/cnn_0003', '0', '8', 'approach', '01', '2', 'Linda_Hamilton', '*', '(V*)', '-'], ['me', 'PRP', '(NP*))))))', 'O', 'bc/cnn/00/cnn_0003', '0', '9', '-', '-', '-', 'Linda_Hamilton', '*)', '(ARG2*)', '(76)'], ['/.', '.', '*))', 'O', 'bc/cnn/00/cnn_0003', '0', '10', '-', '-', '-', 'Linda_Hamilton', '*', '*', '-'], [], ['but', 'CC', '(TOP(S*', 'O', 'bc/cnn/00/cnn_0003', '0', '0', '-', '-', '-', 'Linda_Hamilton', '*', '*', '-'], ['I', 'PRP', '(S(NP*)', 'O', 'bc/cnn/00/cnn_0003', '0', '1', '-', '-', '-', 'Linda_Hamilton', '*', '(ARG0*)', '(76)'], ['am', 'VBP', '(VP*', 'O', 'bc/cnn/00/cnn_0003', '0', '2', 'be', '03', '-', 'Linda_Hamilton', '(V*)', '*', '-'], ['not', 'RB', '*', 'O', 'bc/cnn/00/cnn_0003', '0', '3', '-', '-', '-', 'Linda_Hamilton', '*', '(ARGM-NEG*)', '-'], ['selling', 'VBG', '(VP*', 'O', 'bc/cnn/00/cnn_0003', '0', '4', 'sell', '01', '1', 'Linda_Hamilton', '*', '(V*)', '-'], ['medicine', 'NN', '(NP*', 'O', 'bc/cnn/00/cnn_0003', '0', '5', 'medicine', '-', '1', 'Linda_Hamilton', '*', '(ARG1*', '-'], ['or', 'CC', '*', 'O', 'bc/cnn/00/cnn_0003', '0', '6', '-', '-', '-', 'Linda_Hamilton', '*', '*', '-'], ['pharmaceuticals', 'NNS', '*))))', 'O', 'bc/cnn/00/cnn_0003', '0', '7', '-', '-', '-', 'Linda_Hamilton', '*', '*)', '-'], ['/.', '.', '*))', 'O', 'bc/cnn/00/cnn_0003', '0', '8', '-', '-', '-', 'Linda_Hamilton', '*', '*', '-'], [], ['I', 'PRP', '(TOP(S(NP*)', 'O', 'bc/cnn/00/cnn_0003', '0', '0', '-', '-', '-', 'Linda_Hamilton', '(ARG1*)', '*', '*', '(76)'], [\"'m\", 'VBP', '(VP*', 'O', 'bc/cnn/00/cnn_0003', '0', '1', 'be', '01', '1', 'Linda_Hamilton', '(V*)', '*', '*', '-'], ['sort', 'RB', '(PP(ADVP*', 'O', 'bc/cnn/00/cnn_0003', '0', '2', '-', '-', '-', 'Linda_Hamilton', '(ARG2*', '*', '*', '-'], ['of', 'RB', '*)', 'O', 'bc/cnn/00/cnn_0003', '0', '3', '-', '-', '-', 'Linda_Hamilton', '*', '*', '*', '-'], ['about', 'IN', '*', 'O', 'bc/cnn/00/cnn_0003', '0', '4', '-', '-', '-', 'Linda_Hamilton', '*', '*', '*', '-'], ['selling', 'VBG', '(S(VP*', 'O', 'bc/cnn/00/cnn_0003', '0', '5', 'sell', '01', '2', 'Linda_Hamilton', '*', '(V*)', '*', '-'], ['a', 'DT', '(NP(NP*', 'O', 'bc/cnn/00/cnn_0003', '0', '6', '-', '-', '-', 'Linda_Hamilton', '*', '(ARG1*', '*', '-'], ['full', 'JJ', '(ADJP*', 'O', 'bc/cnn/00/cnn_0003', '0', '7', '-', '-', '-', 'Linda_Hamilton', '*', '*', '(ARG2*', '-'], ['body', 'NN', '*)', 'O', 'bc/cnn/00/cnn_0003', '0', '8', 'body', '-', '2', 'Linda_Hamilton', '*', '*', '*)', '-'], ['approach', 'NN', '*)', 'O', 'bc/cnn/00/cnn_0003', '0', '9', 'approach', '02', '3', 'Linda_Hamilton', '*', '*', '(V*)', '-'], ['to', 'IN', '(PP*', 'O', 'bc/cnn/00/cnn_0003', '0', '10', '-', '-', '-', 'Linda_Hamilton', '*', '*', '(ARG1*', '-'], ['wellness', 'NN', '(NP*)))))))', 'O', 'bc/cnn/00/cnn_0003', '0', '11', '-', '-', '-', 'Linda_Hamilton', '*)', '*)', '*)', '-'], ['/.', '.', '*))', 'O', 'bc/cnn/00/cnn_0003', '0', '12', '-', '-', '-', 'Linda_Hamilton', '*', '*', '*', '-'], [], ['Um', 'UH', '(TOP(S(INTJ*)', 'O', 'bc/cnn/00/cnn_0003', '0', '0', '-', '-', '-', 'Linda_Hamilton', '(ARGM-DIS*)', '*', '-'], ['there', 'EX', '(NP*)', 'O', 'bc/cnn/00/cnn_0003', '0', '1', '-', '-', '-', 'Linda_Hamilton', '*', '*', '-'], [\"'s\", 'VBZ', '(VP*', 'O', 'bc/cnn/00/cnn_0003', '0', '2', 'be', '02', '3', 'Linda_Hamilton', '(V*)', '*', '-'], ['a', 'DT', '(NP(NP*', 'O', 'bc/cnn/00/cnn_0003', '0', '3', '-', '-', '-', 'Linda_Hamilton', '(ARG1*', '*', '-'], ['big', 'JJ', '*', 'O', 'bc/cnn/00/cnn_0003', '0', '4', '-', '-', '-', 'Linda_Hamilton', '*', '*', '-'], ['gap', 'NN', '*)', 'O', 'bc/cnn/00/cnn_0003', '0', '5', 'gap', '-', '4', 'Linda_Hamilton', '*', '*', '-'], ['between', 'IN', '(PP*', 'O', 'bc/cnn/00/cnn_0003', '0', '6', '-', '-', '-', 'Linda_Hamilton', '*', '*', '-'], ['those', 'DT', '(NP(NP(NP*)', 'O', 'bc/cnn/00/cnn_0003', '0', '7', '-', '-', '-', 'Linda_Hamilton', '*', '(ARG1*)', '-'], ['that', 'WDT', '(SBAR(WHNP*)', 'O', 'bc/cnn/00/cnn_0003', '0', '8', '-', '-', '-', 'Linda_Hamilton', '*', '(R-ARG1*)', '-'], ['are', 'VBP', '(S(VP*', 'O', 'bc/cnn/00/cnn_0003', '0', '9', 'be', '01', '1', 'Linda_Hamilton', '*', '(V*)', '-'], ['mentally', 'RB', '(ADJP*', 'O', 'bc/cnn/00/cnn_0003', '0', '10', '-', '-', '-', 'Linda_Hamilton', '*', '(ARG2*', '-'], ['ill', 'JJ', '*)))))', 'O', 'bc/cnn/00/cnn_0003', '0', '11', '-', '-', '-', 'Linda_Hamilton', '*', '*)', '-'], ['and', 'CC', '*', 'O', 'bc/cnn/00/cnn_0003', '0', '12', '-', '-', '-', 'Linda_Hamilton', '*', '*', '-'], ['the', 'DT', '(NP*', 'O', 'bc/cnn/00/cnn_0003', '0', '13', '-', '-', '-', 'Linda_Hamilton', '*', '*', '-'], ['general', 'JJ', '*', 'O', 'bc/cnn/00/cnn_0003', '0', '14', '-', '-', '-', 'Linda_Hamilton', '*', '*', '-'], ['population', 'NN', '*)))))', 'O', 'bc/cnn/00/cnn_0003', '0', '15', 'population', '-', '2', 'Linda_Hamilton', '*)', '*', '-'], ['/.', '.', '*))', 'O', 'bc/cnn/00/cnn_0003', '0', '16', '-', '-', '-', 'Linda_Hamilton', '*', '*', '-'], [], ['A', 'DT', '(TOP(FRAG(NP*', 'O', 'bc/cnn/00/cnn_0000', '0', '0', '-', '-', '-', 'speaker1', '*', '*', '*', '(38'], ['much', 'RB', '(ADJP*', 'O', 'bc/cnn/00/cnn_0000', '0', '1', '-', '-', '-', 'speaker1', '*', '*', '*', '-'], ['better', 'JJR', '*))', 'O', 'bc/cnn/00/cnn_0000', '0', '2', '-', '-', '-', 'speaker1', '*', '*', '*', '-'], ['looking', 'VBG', '(VP*', 'O', 'bc/cnn/00/cnn_0000', '0', '3', 'look', '01', '1', 'speaker1', '(V*)', '*', '*', '-'], ['News', 'NNP', '(NP*', 'B-WORK_OF_ART', 'bc/cnn/00/cnn_0000', '0', '4', '-', '-', '-', 'speaker1', '(ARG1*', '*', '*', '-'], ['Night', 'NN', '*)', 'I-WORK_OF_ART', 'bc/cnn/00/cnn_0000', '0', '5', 'night', '-', '1', 'speaker1', '*)', '*', '*', '38)'], ['I', 'PRP', '(SBAR(S(NP*)', 'O', 'bc/cnn/00/cnn_0000', '0', '6', '-', '-', '-', 'speaker1', '*', '(ARG0*)', '*', '(51)'], ['might', 'MD', '(VP*', 'O', 'bc/cnn/00/cnn_0000', '0', '7', '-', '-', '-', 'speaker1', '*', '(ARGM-MOD*)', '*', '-'], ['add', 'VB', '(VP*', 'O', 'bc/cnn/00/cnn_0000', '0', '8', 'add', '02', '1', 'speaker1', '*', '(V*)', '*', '-'], ['as', 'IN', '(SBAR*', 'O', 'bc/cnn/00/cnn_0000', '0', '9', '-', '-', '-', 'speaker1', '*', '(ARGM-CAU*', '*', '-'], ['Paula', 'NNP', '(S(NP*', 'B-PERSON', 'bc/cnn/00/cnn_0000', '0', '10', '-', '-', '-', 'speaker1', '*', '*', '(ARG1*', '(133'], ['Zahn', 'NNP', '*)', 'I-PERSON', 'bc/cnn/00/cnn_0000', '0', '11', '-', '-', '-', 'speaker1', '*', '*', '*)', '133)'], ['sits', 'VBZ', '(VP*', 'O', 'bc/cnn/00/cnn_0000', '0', '12', 'sit', '01', '1', 'speaker1', '*', '*', '(V*)', '-'], ['in', 'IN', '(PP*', 'O', 'bc/cnn/00/cnn_0000', '0', '13', '-', '-', '-', 'speaker1', '*', '*', '(ARG2*', '-'], ['for', 'IN', '(PP*', 'O', 'bc/cnn/00/cnn_0000', '0', '14', '-', '-', '-', 'speaker1', '*', '*', '*', '-'], ['Anderson', 'NNP', '(NP*', 'B-PERSON', 'bc/cnn/00/cnn_0000', '0', '15', '-', '-', '-', 'speaker1', '*', '*', '*', '(71|(105)'], ['and', 'CC', '*', 'O', 'bc/cnn/00/cnn_0000', '0', '16', '-', '-', '-', 'speaker1', '*', '*', '*', '-'], ['Aaron', 'NNP', '*)))))))))))', 'B-PERSON', 'bc/cnn/00/cnn_0000', '0', '17', '-', '-', '-', 'speaker1', '*', '*)', '*)', '(124)|71)'], ['/.', '.', '*))', 'O', 'bc/cnn/00/cnn_0000', '0', '18', '-', '-', '-', 'speaker1', '*', '*', '*', '-'], [], ['They', 'PRP', '(TOP(S(NP*)', 'O', 'bc/cnn/00/cnn_0000', '0', '0', '-', '-', '-', 'speaker1', '(71)'], [\"'re\", 'VBP', '(VP*', 'O', 'bc/cnn/00/cnn_0000', '0', '1', 'be', '-', '1', 'speaker1', '-'], ['both', 'DT', '*', 'O', 'bc/cnn/00/cnn_0000', '0', '2', '-', '-', '-', 'speaker1', '-'], ['off', 'RB', '(ADVP*))', 'O', 'bc/cnn/00/cnn_0000', '0', '3', '-', '-', '-', 'speaker1', '-'], ['/-', '.', '*))', 'O', 'bc/cnn/00/cnn_0000', '0', '4', '-', '-', '-', 'speaker1', '-'], [], ['Look', 'VB', '(TOP(S(VP*', 'O', 'bc/cnn/00/cnn_0000', '0', '0', 'look', '-', '1', 'speaker1', '-'], ['at', 'IN', '(PP*', 'O', 'bc/cnn/00/cnn_0000', '0', '1', '-', '-', '-', 'speaker1', '-'], ['that', 'DT', '(NP*)))', 'O', 'bc/cnn/00/cnn_0000', '0', '2', '-', '-', '-', 'speaker1', '(133)'], ['/.', '.', '*))', 'O', 'bc/cnn/00/cnn_0000', '0', '3', '-', '-', '-', 'speaker1', '-']]}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restoring parameters from ../results/checkpoints/best\\best.ckpt-4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[saver.py:1270 - restore() ] Restoring parameters from ../results/checkpoints/best\\best.ckpt-4\n",
      "[main.py:479 - load_model() ] Invoked load_model method\n",
      "[main.py:480 - load_model() ] With parameters : \n",
      "[main.py:481 - load_model() ] None\n",
      "[main.py:482 - load_model() ] ()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[main.py:483 - load_model() ] {'predictData': '../data/sample/ner_test_input.txt', 'loadForPredict': True, 'writeInputToFile': False, 'model': <model.Elmo.ElmoModel object at 0x000001F265323630>, 'sess': <tensorflow.python.client.session.Session object at 0x000001F20D60AE10>, 'saver': <tensorflow.python.training.saver.Saver object at 0x000001F20CABD978>, 'trainedData': [['Yes', 'UH', '(TOP(S(INTJ*)', 'O', 'bc/cnn/00/cnn_0003', '0', '0', '-', '-', '-', 'Linda_Hamilton', '*', '-'], ['they', 'PRP', '(NP*)', 'O', 'bc/cnn/00/cnn_0003', '0', '1', '-', '-', '-', 'Linda_Hamilton', '*', '(15)'], ['did', 'VBD', '(VP*)', 'O', 'bc/cnn/00/cnn_0003', '0', '2', 'do', '01', '-', 'Linda_Hamilton', '(V*)', '-'], ['/.', '.', '*))', 'O', 'bc/cnn/00/cnn_0003', '0', '3', '-', '-', '-', 'Linda_Hamilton', '*', '-'], [], ['and', 'CC', '(TOP(S*', 'O', 'bc/cnn/00/cnn_0003', '0', '0', '-', '-', '-', 'Linda_Hamilton', '(ARGM-DIS*)', '*', '-'], ['they', 'PRP', '(NP*)', 'O', 'bc/cnn/00/cnn_0003', '0', '1', '-', '-', '-', 'Linda_Hamilton', '(ARG1*)', '*', '(15)'], ['were', 'VBD', '(VP*', 'O', 'bc/cnn/00/cnn_0003', '0', '2', 'be', '01', '2', 'Linda_Hamilton', '(V*)', '*', '-'], ['not', 'RB', '*', 'O', 'bc/cnn/00/cnn_0003', '0', '3', '-', '-', '-', 'Linda_Hamilton', '(ARGM-NEG*)', '*', '-'], ['the', 'DT', '(NP(NP*', 'O', 'bc/cnn/00/cnn_0003', '0', '4', '-', '-', '-', 'Linda_Hamilton', '(ARG2*', '(ARG1*', '-'], ['first', 'JJ', '*', 'B-ORDINAL', 'bc/cnn/00/cnn_0003', '0', '5', '-', '-', '-', 'Linda_Hamilton', '*', '*', '-'], ['company', 'NN', '*)', 'O', 'bc/cnn/00/cnn_0003', '0', '6', 'company', '-', '1', 'Linda_Hamilton', '*', '*)', '-'], ['that', 'WDT', '(SBAR(WHNP*)', 'O', 'bc/cnn/00/cnn_0003', '0', '7', '-', '-', '-', 'Linda_Hamilton', '*', '(R-ARG1*)', '-'], ['approached', 'VBD', '(S(VP*', 'O', 'bc/cnn/00/cnn_0003', '0', '8', 'approach', '01', '2', 'Linda_Hamilton', '*', '(V*)', '-'], ['me', 'PRP', '(NP*))))))', 'O', 'bc/cnn/00/cnn_0003', '0', '9', '-', '-', '-', 'Linda_Hamilton', '*)', '(ARG2*)', '(76)'], ['/.', '.', '*))', 'O', 'bc/cnn/00/cnn_0003', '0', '10', '-', '-', '-', 'Linda_Hamilton', '*', '*', '-'], [], ['but', 'CC', '(TOP(S*', 'O', 'bc/cnn/00/cnn_0003', '0', '0', '-', '-', '-', 'Linda_Hamilton', '*', '*', '-'], ['I', 'PRP', '(S(NP*)', 'O', 'bc/cnn/00/cnn_0003', '0', '1', '-', '-', '-', 'Linda_Hamilton', '*', '(ARG0*)', '(76)'], ['am', 'VBP', '(VP*', 'O', 'bc/cnn/00/cnn_0003', '0', '2', 'be', '03', '-', 'Linda_Hamilton', '(V*)', '*', '-'], ['not', 'RB', '*', 'O', 'bc/cnn/00/cnn_0003', '0', '3', '-', '-', '-', 'Linda_Hamilton', '*', '(ARGM-NEG*)', '-'], ['selling', 'VBG', '(VP*', 'O', 'bc/cnn/00/cnn_0003', '0', '4', 'sell', '01', '1', 'Linda_Hamilton', '*', '(V*)', '-'], ['medicine', 'NN', '(NP*', 'O', 'bc/cnn/00/cnn_0003', '0', '5', 'medicine', '-', '1', 'Linda_Hamilton', '*', '(ARG1*', '-'], ['or', 'CC', '*', 'O', 'bc/cnn/00/cnn_0003', '0', '6', '-', '-', '-', 'Linda_Hamilton', '*', '*', '-'], ['pharmaceuticals', 'NNS', '*))))', 'O', 'bc/cnn/00/cnn_0003', '0', '7', '-', '-', '-', 'Linda_Hamilton', '*', '*)', '-'], ['/.', '.', '*))', 'O', 'bc/cnn/00/cnn_0003', '0', '8', '-', '-', '-', 'Linda_Hamilton', '*', '*', '-'], [], ['I', 'PRP', '(TOP(S(NP*)', 'O', 'bc/cnn/00/cnn_0003', '0', '0', '-', '-', '-', 'Linda_Hamilton', '(ARG1*)', '*', '*', '(76)'], [\"'m\", 'VBP', '(VP*', 'O', 'bc/cnn/00/cnn_0003', '0', '1', 'be', '01', '1', 'Linda_Hamilton', '(V*)', '*', '*', '-'], ['sort', 'RB', '(PP(ADVP*', 'O', 'bc/cnn/00/cnn_0003', '0', '2', '-', '-', '-', 'Linda_Hamilton', '(ARG2*', '*', '*', '-'], ['of', 'RB', '*)', 'O', 'bc/cnn/00/cnn_0003', '0', '3', '-', '-', '-', 'Linda_Hamilton', '*', '*', '*', '-'], ['about', 'IN', '*', 'O', 'bc/cnn/00/cnn_0003', '0', '4', '-', '-', '-', 'Linda_Hamilton', '*', '*', '*', '-'], ['selling', 'VBG', '(S(VP*', 'O', 'bc/cnn/00/cnn_0003', '0', '5', 'sell', '01', '2', 'Linda_Hamilton', '*', '(V*)', '*', '-'], ['a', 'DT', '(NP(NP*', 'O', 'bc/cnn/00/cnn_0003', '0', '6', '-', '-', '-', 'Linda_Hamilton', '*', '(ARG1*', '*', '-'], ['full', 'JJ', '(ADJP*', 'O', 'bc/cnn/00/cnn_0003', '0', '7', '-', '-', '-', 'Linda_Hamilton', '*', '*', '(ARG2*', '-'], ['body', 'NN', '*)', 'O', 'bc/cnn/00/cnn_0003', '0', '8', 'body', '-', '2', 'Linda_Hamilton', '*', '*', '*)', '-'], ['approach', 'NN', '*)', 'O', 'bc/cnn/00/cnn_0003', '0', '9', 'approach', '02', '3', 'Linda_Hamilton', '*', '*', '(V*)', '-'], ['to', 'IN', '(PP*', 'O', 'bc/cnn/00/cnn_0003', '0', '10', '-', '-', '-', 'Linda_Hamilton', '*', '*', '(ARG1*', '-'], ['wellness', 'NN', '(NP*)))))))', 'O', 'bc/cnn/00/cnn_0003', '0', '11', '-', '-', '-', 'Linda_Hamilton', '*)', '*)', '*)', '-'], ['/.', '.', '*))', 'O', 'bc/cnn/00/cnn_0003', '0', '12', '-', '-', '-', 'Linda_Hamilton', '*', '*', '*', '-'], [], ['Um', 'UH', '(TOP(S(INTJ*)', 'O', 'bc/cnn/00/cnn_0003', '0', '0', '-', '-', '-', 'Linda_Hamilton', '(ARGM-DIS*)', '*', '-'], ['there', 'EX', '(NP*)', 'O', 'bc/cnn/00/cnn_0003', '0', '1', '-', '-', '-', 'Linda_Hamilton', '*', '*', '-'], [\"'s\", 'VBZ', '(VP*', 'O', 'bc/cnn/00/cnn_0003', '0', '2', 'be', '02', '3', 'Linda_Hamilton', '(V*)', '*', '-'], ['a', 'DT', '(NP(NP*', 'O', 'bc/cnn/00/cnn_0003', '0', '3', '-', '-', '-', 'Linda_Hamilton', '(ARG1*', '*', '-'], ['big', 'JJ', '*', 'O', 'bc/cnn/00/cnn_0003', '0', '4', '-', '-', '-', 'Linda_Hamilton', '*', '*', '-'], ['gap', 'NN', '*)', 'O', 'bc/cnn/00/cnn_0003', '0', '5', 'gap', '-', '4', 'Linda_Hamilton', '*', '*', '-'], ['between', 'IN', '(PP*', 'O', 'bc/cnn/00/cnn_0003', '0', '6', '-', '-', '-', 'Linda_Hamilton', '*', '*', '-'], ['those', 'DT', '(NP(NP(NP*)', 'O', 'bc/cnn/00/cnn_0003', '0', '7', '-', '-', '-', 'Linda_Hamilton', '*', '(ARG1*)', '-'], ['that', 'WDT', '(SBAR(WHNP*)', 'O', 'bc/cnn/00/cnn_0003', '0', '8', '-', '-', '-', 'Linda_Hamilton', '*', '(R-ARG1*)', '-'], ['are', 'VBP', '(S(VP*', 'O', 'bc/cnn/00/cnn_0003', '0', '9', 'be', '01', '1', 'Linda_Hamilton', '*', '(V*)', '-'], ['mentally', 'RB', '(ADJP*', 'O', 'bc/cnn/00/cnn_0003', '0', '10', '-', '-', '-', 'Linda_Hamilton', '*', '(ARG2*', '-'], ['ill', 'JJ', '*)))))', 'O', 'bc/cnn/00/cnn_0003', '0', '11', '-', '-', '-', 'Linda_Hamilton', '*', '*)', '-'], ['and', 'CC', '*', 'O', 'bc/cnn/00/cnn_0003', '0', '12', '-', '-', '-', 'Linda_Hamilton', '*', '*', '-'], ['the', 'DT', '(NP*', 'O', 'bc/cnn/00/cnn_0003', '0', '13', '-', '-', '-', 'Linda_Hamilton', '*', '*', '-'], ['general', 'JJ', '*', 'O', 'bc/cnn/00/cnn_0003', '0', '14', '-', '-', '-', 'Linda_Hamilton', '*', '*', '-'], ['population', 'NN', '*)))))', 'O', 'bc/cnn/00/cnn_0003', '0', '15', 'population', '-', '2', 'Linda_Hamilton', '*)', '*', '-'], ['/.', '.', '*))', 'O', 'bc/cnn/00/cnn_0003', '0', '16', '-', '-', '-', 'Linda_Hamilton', '*', '*', '-'], [], ['A', 'DT', '(TOP(FRAG(NP*', 'O', 'bc/cnn/00/cnn_0000', '0', '0', '-', '-', '-', 'speaker1', '*', '*', '*', '(38'], ['much', 'RB', '(ADJP*', 'O', 'bc/cnn/00/cnn_0000', '0', '1', '-', '-', '-', 'speaker1', '*', '*', '*', '-'], ['better', 'JJR', '*))', 'O', 'bc/cnn/00/cnn_0000', '0', '2', '-', '-', '-', 'speaker1', '*', '*', '*', '-'], ['looking', 'VBG', '(VP*', 'O', 'bc/cnn/00/cnn_0000', '0', '3', 'look', '01', '1', 'speaker1', '(V*)', '*', '*', '-'], ['News', 'NNP', '(NP*', 'B-WORK_OF_ART', 'bc/cnn/00/cnn_0000', '0', '4', '-', '-', '-', 'speaker1', '(ARG1*', '*', '*', '-'], ['Night', 'NN', '*)', 'I-WORK_OF_ART', 'bc/cnn/00/cnn_0000', '0', '5', 'night', '-', '1', 'speaker1', '*)', '*', '*', '38)'], ['I', 'PRP', '(SBAR(S(NP*)', 'O', 'bc/cnn/00/cnn_0000', '0', '6', '-', '-', '-', 'speaker1', '*', '(ARG0*)', '*', '(51)'], ['might', 'MD', '(VP*', 'O', 'bc/cnn/00/cnn_0000', '0', '7', '-', '-', '-', 'speaker1', '*', '(ARGM-MOD*)', '*', '-'], ['add', 'VB', '(VP*', 'O', 'bc/cnn/00/cnn_0000', '0', '8', 'add', '02', '1', 'speaker1', '*', '(V*)', '*', '-'], ['as', 'IN', '(SBAR*', 'O', 'bc/cnn/00/cnn_0000', '0', '9', '-', '-', '-', 'speaker1', '*', '(ARGM-CAU*', '*', '-'], ['Paula', 'NNP', '(S(NP*', 'B-PERSON', 'bc/cnn/00/cnn_0000', '0', '10', '-', '-', '-', 'speaker1', '*', '*', '(ARG1*', '(133'], ['Zahn', 'NNP', '*)', 'I-PERSON', 'bc/cnn/00/cnn_0000', '0', '11', '-', '-', '-', 'speaker1', '*', '*', '*)', '133)'], ['sits', 'VBZ', '(VP*', 'O', 'bc/cnn/00/cnn_0000', '0', '12', 'sit', '01', '1', 'speaker1', '*', '*', '(V*)', '-'], ['in', 'IN', '(PP*', 'O', 'bc/cnn/00/cnn_0000', '0', '13', '-', '-', '-', 'speaker1', '*', '*', '(ARG2*', '-'], ['for', 'IN', '(PP*', 'O', 'bc/cnn/00/cnn_0000', '0', '14', '-', '-', '-', 'speaker1', '*', '*', '*', '-'], ['Anderson', 'NNP', '(NP*', 'B-PERSON', 'bc/cnn/00/cnn_0000', '0', '15', '-', '-', '-', 'speaker1', '*', '*', '*', '(71|(105)'], ['and', 'CC', '*', 'O', 'bc/cnn/00/cnn_0000', '0', '16', '-', '-', '-', 'speaker1', '*', '*', '*', '-'], ['Aaron', 'NNP', '*)))))))))))', 'B-PERSON', 'bc/cnn/00/cnn_0000', '0', '17', '-', '-', '-', 'speaker1', '*', '*)', '*)', '(124)|71)'], ['/.', '.', '*))', 'O', 'bc/cnn/00/cnn_0000', '0', '18', '-', '-', '-', 'speaker1', '*', '*', '*', '-'], [], ['They', 'PRP', '(TOP(S(NP*)', 'O', 'bc/cnn/00/cnn_0000', '0', '0', '-', '-', '-', 'speaker1', '(71)'], [\"'re\", 'VBP', '(VP*', 'O', 'bc/cnn/00/cnn_0000', '0', '1', 'be', '-', '1', 'speaker1', '-'], ['both', 'DT', '*', 'O', 'bc/cnn/00/cnn_0000', '0', '2', '-', '-', '-', 'speaker1', '-'], ['off', 'RB', '(ADVP*))', 'O', 'bc/cnn/00/cnn_0000', '0', '3', '-', '-', '-', 'speaker1', '-'], ['/-', '.', '*))', 'O', 'bc/cnn/00/cnn_0000', '0', '4', '-', '-', '-', 'speaker1', '-'], [], ['Look', 'VB', '(TOP(S(VP*', 'O', 'bc/cnn/00/cnn_0000', '0', '0', 'look', '-', '1', 'speaker1', '-'], ['at', 'IN', '(PP*', 'O', 'bc/cnn/00/cnn_0000', '0', '1', '-', '-', '-', 'speaker1', '-'], ['that', 'DT', '(NP*)))', 'O', 'bc/cnn/00/cnn_0000', '0', '2', '-', '-', '-', 'speaker1', '(133)'], ['/.', '.', '*))', 'O', 'bc/cnn/00/cnn_0000', '0', '3', '-', '-', '-', 'speaker1', '-']]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[main.py:530 - data_converter() ] Invoked data_converter method\n",
      "[main.py:531 - data_converter() ] With parameters : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[main.py:532 - data_converter() ] {'test': [['Yes', 'UH', '(TOP(S(INTJ*)', 'O', 'bc/cnn/00/cnn_0003', '0', '0', '-', '-', '-', 'Linda_Hamilton', '*', '-'], ['they', 'PRP', '(NP*)', 'O', 'bc/cnn/00/cnn_0003', '0', '1', '-', '-', '-', 'Linda_Hamilton', '*', '(15)'], ['did', 'VBD', '(VP*)', 'O', 'bc/cnn/00/cnn_0003', '0', '2', 'do', '01', '-', 'Linda_Hamilton', '(V*)', '-'], ['/.', '.', '*))', 'O', 'bc/cnn/00/cnn_0003', '0', '3', '-', '-', '-', 'Linda_Hamilton', '*', '-'], [], ['and', 'CC', '(TOP(S*', 'O', 'bc/cnn/00/cnn_0003', '0', '0', '-', '-', '-', 'Linda_Hamilton', '(ARGM-DIS*)', '*', '-'], ['they', 'PRP', '(NP*)', 'O', 'bc/cnn/00/cnn_0003', '0', '1', '-', '-', '-', 'Linda_Hamilton', '(ARG1*)', '*', '(15)'], ['were', 'VBD', '(VP*', 'O', 'bc/cnn/00/cnn_0003', '0', '2', 'be', '01', '2', 'Linda_Hamilton', '(V*)', '*', '-'], ['not', 'RB', '*', 'O', 'bc/cnn/00/cnn_0003', '0', '3', '-', '-', '-', 'Linda_Hamilton', '(ARGM-NEG*)', '*', '-'], ['the', 'DT', '(NP(NP*', 'O', 'bc/cnn/00/cnn_0003', '0', '4', '-', '-', '-', 'Linda_Hamilton', '(ARG2*', '(ARG1*', '-'], ['first', 'JJ', '*', 'B-ORDINAL', 'bc/cnn/00/cnn_0003', '0', '5', '-', '-', '-', 'Linda_Hamilton', '*', '*', '-'], ['company', 'NN', '*)', 'O', 'bc/cnn/00/cnn_0003', '0', '6', 'company', '-', '1', 'Linda_Hamilton', '*', '*)', '-'], ['that', 'WDT', '(SBAR(WHNP*)', 'O', 'bc/cnn/00/cnn_0003', '0', '7', '-', '-', '-', 'Linda_Hamilton', '*', '(R-ARG1*)', '-'], ['approached', 'VBD', '(S(VP*', 'O', 'bc/cnn/00/cnn_0003', '0', '8', 'approach', '01', '2', 'Linda_Hamilton', '*', '(V*)', '-'], ['me', 'PRP', '(NP*))))))', 'O', 'bc/cnn/00/cnn_0003', '0', '9', '-', '-', '-', 'Linda_Hamilton', '*)', '(ARG2*)', '(76)'], ['/.', '.', '*))', 'O', 'bc/cnn/00/cnn_0003', '0', '10', '-', '-', '-', 'Linda_Hamilton', '*', '*', '-'], [], ['but', 'CC', '(TOP(S*', 'O', 'bc/cnn/00/cnn_0003', '0', '0', '-', '-', '-', 'Linda_Hamilton', '*', '*', '-'], ['I', 'PRP', '(S(NP*)', 'O', 'bc/cnn/00/cnn_0003', '0', '1', '-', '-', '-', 'Linda_Hamilton', '*', '(ARG0*)', '(76)'], ['am', 'VBP', '(VP*', 'O', 'bc/cnn/00/cnn_0003', '0', '2', 'be', '03', '-', 'Linda_Hamilton', '(V*)', '*', '-'], ['not', 'RB', '*', 'O', 'bc/cnn/00/cnn_0003', '0', '3', '-', '-', '-', 'Linda_Hamilton', '*', '(ARGM-NEG*)', '-'], ['selling', 'VBG', '(VP*', 'O', 'bc/cnn/00/cnn_0003', '0', '4', 'sell', '01', '1', 'Linda_Hamilton', '*', '(V*)', '-'], ['medicine', 'NN', '(NP*', 'O', 'bc/cnn/00/cnn_0003', '0', '5', 'medicine', '-', '1', 'Linda_Hamilton', '*', '(ARG1*', '-'], ['or', 'CC', '*', 'O', 'bc/cnn/00/cnn_0003', '0', '6', '-', '-', '-', 'Linda_Hamilton', '*', '*', '-'], ['pharmaceuticals', 'NNS', '*))))', 'O', 'bc/cnn/00/cnn_0003', '0', '7', '-', '-', '-', 'Linda_Hamilton', '*', '*)', '-'], ['/.', '.', '*))', 'O', 'bc/cnn/00/cnn_0003', '0', '8', '-', '-', '-', 'Linda_Hamilton', '*', '*', '-'], [], ['I', 'PRP', '(TOP(S(NP*)', 'O', 'bc/cnn/00/cnn_0003', '0', '0', '-', '-', '-', 'Linda_Hamilton', '(ARG1*)', '*', '*', '(76)'], [\"'m\", 'VBP', '(VP*', 'O', 'bc/cnn/00/cnn_0003', '0', '1', 'be', '01', '1', 'Linda_Hamilton', '(V*)', '*', '*', '-'], ['sort', 'RB', '(PP(ADVP*', 'O', 'bc/cnn/00/cnn_0003', '0', '2', '-', '-', '-', 'Linda_Hamilton', '(ARG2*', '*', '*', '-'], ['of', 'RB', '*)', 'O', 'bc/cnn/00/cnn_0003', '0', '3', '-', '-', '-', 'Linda_Hamilton', '*', '*', '*', '-'], ['about', 'IN', '*', 'O', 'bc/cnn/00/cnn_0003', '0', '4', '-', '-', '-', 'Linda_Hamilton', '*', '*', '*', '-'], ['selling', 'VBG', '(S(VP*', 'O', 'bc/cnn/00/cnn_0003', '0', '5', 'sell', '01', '2', 'Linda_Hamilton', '*', '(V*)', '*', '-'], ['a', 'DT', '(NP(NP*', 'O', 'bc/cnn/00/cnn_0003', '0', '6', '-', '-', '-', 'Linda_Hamilton', '*', '(ARG1*', '*', '-'], ['full', 'JJ', '(ADJP*', 'O', 'bc/cnn/00/cnn_0003', '0', '7', '-', '-', '-', 'Linda_Hamilton', '*', '*', '(ARG2*', '-'], ['body', 'NN', '*)', 'O', 'bc/cnn/00/cnn_0003', '0', '8', 'body', '-', '2', 'Linda_Hamilton', '*', '*', '*)', '-'], ['approach', 'NN', '*)', 'O', 'bc/cnn/00/cnn_0003', '0', '9', 'approach', '02', '3', 'Linda_Hamilton', '*', '*', '(V*)', '-'], ['to', 'IN', '(PP*', 'O', 'bc/cnn/00/cnn_0003', '0', '10', '-', '-', '-', 'Linda_Hamilton', '*', '*', '(ARG1*', '-'], ['wellness', 'NN', '(NP*)))))))', 'O', 'bc/cnn/00/cnn_0003', '0', '11', '-', '-', '-', 'Linda_Hamilton', '*)', '*)', '*)', '-'], ['/.', '.', '*))', 'O', 'bc/cnn/00/cnn_0003', '0', '12', '-', '-', '-', 'Linda_Hamilton', '*', '*', '*', '-'], [], ['Um', 'UH', '(TOP(S(INTJ*)', 'O', 'bc/cnn/00/cnn_0003', '0', '0', '-', '-', '-', 'Linda_Hamilton', '(ARGM-DIS*)', '*', '-'], ['there', 'EX', '(NP*)', 'O', 'bc/cnn/00/cnn_0003', '0', '1', '-', '-', '-', 'Linda_Hamilton', '*', '*', '-'], [\"'s\", 'VBZ', '(VP*', 'O', 'bc/cnn/00/cnn_0003', '0', '2', 'be', '02', '3', 'Linda_Hamilton', '(V*)', '*', '-'], ['a', 'DT', '(NP(NP*', 'O', 'bc/cnn/00/cnn_0003', '0', '3', '-', '-', '-', 'Linda_Hamilton', '(ARG1*', '*', '-'], ['big', 'JJ', '*', 'O', 'bc/cnn/00/cnn_0003', '0', '4', '-', '-', '-', 'Linda_Hamilton', '*', '*', '-'], ['gap', 'NN', '*)', 'O', 'bc/cnn/00/cnn_0003', '0', '5', 'gap', '-', '4', 'Linda_Hamilton', '*', '*', '-'], ['between', 'IN', '(PP*', 'O', 'bc/cnn/00/cnn_0003', '0', '6', '-', '-', '-', 'Linda_Hamilton', '*', '*', '-'], ['those', 'DT', '(NP(NP(NP*)', 'O', 'bc/cnn/00/cnn_0003', '0', '7', '-', '-', '-', 'Linda_Hamilton', '*', '(ARG1*)', '-'], ['that', 'WDT', '(SBAR(WHNP*)', 'O', 'bc/cnn/00/cnn_0003', '0', '8', '-', '-', '-', 'Linda_Hamilton', '*', '(R-ARG1*)', '-'], ['are', 'VBP', '(S(VP*', 'O', 'bc/cnn/00/cnn_0003', '0', '9', 'be', '01', '1', 'Linda_Hamilton', '*', '(V*)', '-'], ['mentally', 'RB', '(ADJP*', 'O', 'bc/cnn/00/cnn_0003', '0', '10', '-', '-', '-', 'Linda_Hamilton', '*', '(ARG2*', '-'], ['ill', 'JJ', '*)))))', 'O', 'bc/cnn/00/cnn_0003', '0', '11', '-', '-', '-', 'Linda_Hamilton', '*', '*)', '-'], ['and', 'CC', '*', 'O', 'bc/cnn/00/cnn_0003', '0', '12', '-', '-', '-', 'Linda_Hamilton', '*', '*', '-'], ['the', 'DT', '(NP*', 'O', 'bc/cnn/00/cnn_0003', '0', '13', '-', '-', '-', 'Linda_Hamilton', '*', '*', '-'], ['general', 'JJ', '*', 'O', 'bc/cnn/00/cnn_0003', '0', '14', '-', '-', '-', 'Linda_Hamilton', '*', '*', '-'], ['population', 'NN', '*)))))', 'O', 'bc/cnn/00/cnn_0003', '0', '15', 'population', '-', '2', 'Linda_Hamilton', '*)', '*', '-'], ['/.', '.', '*))', 'O', 'bc/cnn/00/cnn_0003', '0', '16', '-', '-', '-', 'Linda_Hamilton', '*', '*', '-'], [], ['A', 'DT', '(TOP(FRAG(NP*', 'O', 'bc/cnn/00/cnn_0000', '0', '0', '-', '-', '-', 'speaker1', '*', '*', '*', '(38'], ['much', 'RB', '(ADJP*', 'O', 'bc/cnn/00/cnn_0000', '0', '1', '-', '-', '-', 'speaker1', '*', '*', '*', '-'], ['better', 'JJR', '*))', 'O', 'bc/cnn/00/cnn_0000', '0', '2', '-', '-', '-', 'speaker1', '*', '*', '*', '-'], ['looking', 'VBG', '(VP*', 'O', 'bc/cnn/00/cnn_0000', '0', '3', 'look', '01', '1', 'speaker1', '(V*)', '*', '*', '-'], ['News', 'NNP', '(NP*', 'B-WORK_OF_ART', 'bc/cnn/00/cnn_0000', '0', '4', '-', '-', '-', 'speaker1', '(ARG1*', '*', '*', '-'], ['Night', 'NN', '*)', 'I-WORK_OF_ART', 'bc/cnn/00/cnn_0000', '0', '5', 'night', '-', '1', 'speaker1', '*)', '*', '*', '38)'], ['I', 'PRP', '(SBAR(S(NP*)', 'O', 'bc/cnn/00/cnn_0000', '0', '6', '-', '-', '-', 'speaker1', '*', '(ARG0*)', '*', '(51)'], ['might', 'MD', '(VP*', 'O', 'bc/cnn/00/cnn_0000', '0', '7', '-', '-', '-', 'speaker1', '*', '(ARGM-MOD*)', '*', '-'], ['add', 'VB', '(VP*', 'O', 'bc/cnn/00/cnn_0000', '0', '8', 'add', '02', '1', 'speaker1', '*', '(V*)', '*', '-'], ['as', 'IN', '(SBAR*', 'O', 'bc/cnn/00/cnn_0000', '0', '9', '-', '-', '-', 'speaker1', '*', '(ARGM-CAU*', '*', '-'], ['Paula', 'NNP', '(S(NP*', 'B-PERSON', 'bc/cnn/00/cnn_0000', '0', '10', '-', '-', '-', 'speaker1', '*', '*', '(ARG1*', '(133'], ['Zahn', 'NNP', '*)', 'I-PERSON', 'bc/cnn/00/cnn_0000', '0', '11', '-', '-', '-', 'speaker1', '*', '*', '*)', '133)'], ['sits', 'VBZ', '(VP*', 'O', 'bc/cnn/00/cnn_0000', '0', '12', 'sit', '01', '1', 'speaker1', '*', '*', '(V*)', '-'], ['in', 'IN', '(PP*', 'O', 'bc/cnn/00/cnn_0000', '0', '13', '-', '-', '-', 'speaker1', '*', '*', '(ARG2*', '-'], ['for', 'IN', '(PP*', 'O', 'bc/cnn/00/cnn_0000', '0', '14', '-', '-', '-', 'speaker1', '*', '*', '*', '-'], ['Anderson', 'NNP', '(NP*', 'B-PERSON', 'bc/cnn/00/cnn_0000', '0', '15', '-', '-', '-', 'speaker1', '*', '*', '*', '(71|(105)'], ['and', 'CC', '*', 'O', 'bc/cnn/00/cnn_0000', '0', '16', '-', '-', '-', 'speaker1', '*', '*', '*', '-'], ['Aaron', 'NNP', '*)))))))))))', 'B-PERSON', 'bc/cnn/00/cnn_0000', '0', '17', '-', '-', '-', 'speaker1', '*', '*)', '*)', '(124)|71)'], ['/.', '.', '*))', 'O', 'bc/cnn/00/cnn_0000', '0', '18', '-', '-', '-', 'speaker1', '*', '*', '*', '-'], [], ['They', 'PRP', '(TOP(S(NP*)', 'O', 'bc/cnn/00/cnn_0000', '0', '0', '-', '-', '-', 'speaker1', '(71)'], [\"'re\", 'VBP', '(VP*', 'O', 'bc/cnn/00/cnn_0000', '0', '1', 'be', '-', '1', 'speaker1', '-'], ['both', 'DT', '*', 'O', 'bc/cnn/00/cnn_0000', '0', '2', '-', '-', '-', 'speaker1', '-'], ['off', 'RB', '(ADVP*))', 'O', 'bc/cnn/00/cnn_0000', '0', '3', '-', '-', '-', 'speaker1', '-'], ['/-', '.', '*))', 'O', 'bc/cnn/00/cnn_0000', '0', '4', '-', '-', '-', 'speaker1', '-'], [], ['Look', 'VB', '(TOP(S(VP*', 'O', 'bc/cnn/00/cnn_0000', '0', '0', 'look', '-', '1', 'speaker1', '-'], ['at', 'IN', '(PP*', 'O', 'bc/cnn/00/cnn_0000', '0', '1', '-', '-', '-', 'speaker1', '-'], ['that', 'DT', '(NP*)))', 'O', 'bc/cnn/00/cnn_0000', '0', '2', '-', '-', '-', 'speaker1', '(133)'], ['/.', '.', '*))', 'O', 'bc/cnn/00/cnn_0000', '0', '3', '-', '-', '-', 'speaker1', '-'], []], 'train': [['Yes', 'UH', '(TOP(S(INTJ*)', 'O', 'bc/cnn/00/cnn_0003', '0', '0', '-', '-', '-', 'Linda_Hamilton', '*', '-'], ['they', 'PRP', '(NP*)', 'O', 'bc/cnn/00/cnn_0003', '0', '1', '-', '-', '-', 'Linda_Hamilton', '*', '(15)'], ['did', 'VBD', '(VP*)', 'O', 'bc/cnn/00/cnn_0003', '0', '2', 'do', '01', '-', 'Linda_Hamilton', '(V*)', '-'], ['/.', '.', '*))', 'O', 'bc/cnn/00/cnn_0003', '0', '3', '-', '-', '-', 'Linda_Hamilton', '*', '-'], [], ['and', 'CC', '(TOP(S*', 'O', 'bc/cnn/00/cnn_0003', '0', '0', '-', '-', '-', 'Linda_Hamilton', '(ARGM-DIS*)', '*', '-'], ['they', 'PRP', '(NP*)', 'O', 'bc/cnn/00/cnn_0003', '0', '1', '-', '-', '-', 'Linda_Hamilton', '(ARG1*)', '*', '(15)'], ['were', 'VBD', '(VP*', 'O', 'bc/cnn/00/cnn_0003', '0', '2', 'be', '01', '2', 'Linda_Hamilton', '(V*)', '*', '-'], ['not', 'RB', '*', 'O', 'bc/cnn/00/cnn_0003', '0', '3', '-', '-', '-', 'Linda_Hamilton', '(ARGM-NEG*)', '*', '-'], ['the', 'DT', '(NP(NP*', 'O', 'bc/cnn/00/cnn_0003', '0', '4', '-', '-', '-', 'Linda_Hamilton', '(ARG2*', '(ARG1*', '-'], ['first', 'JJ', '*', 'B-ORDINAL', 'bc/cnn/00/cnn_0003', '0', '5', '-', '-', '-', 'Linda_Hamilton', '*', '*', '-'], ['company', 'NN', '*)', 'O', 'bc/cnn/00/cnn_0003', '0', '6', 'company', '-', '1', 'Linda_Hamilton', '*', '*)', '-'], ['that', 'WDT', '(SBAR(WHNP*)', 'O', 'bc/cnn/00/cnn_0003', '0', '7', '-', '-', '-', 'Linda_Hamilton', '*', '(R-ARG1*)', '-'], ['approached', 'VBD', '(S(VP*', 'O', 'bc/cnn/00/cnn_0003', '0', '8', 'approach', '01', '2', 'Linda_Hamilton', '*', '(V*)', '-'], ['me', 'PRP', '(NP*))))))', 'O', 'bc/cnn/00/cnn_0003', '0', '9', '-', '-', '-', 'Linda_Hamilton', '*)', '(ARG2*)', '(76)'], ['/.', '.', '*))', 'O', 'bc/cnn/00/cnn_0003', '0', '10', '-', '-', '-', 'Linda_Hamilton', '*', '*', '-'], [], ['but', 'CC', '(TOP(S*', 'O', 'bc/cnn/00/cnn_0003', '0', '0', '-', '-', '-', 'Linda_Hamilton', '*', '*', '-'], ['I', 'PRP', '(S(NP*)', 'O', 'bc/cnn/00/cnn_0003', '0', '1', '-', '-', '-', 'Linda_Hamilton', '*', '(ARG0*)', '(76)'], ['am', 'VBP', '(VP*', 'O', 'bc/cnn/00/cnn_0003', '0', '2', 'be', '03', '-', 'Linda_Hamilton', '(V*)', '*', '-'], ['not', 'RB', '*', 'O', 'bc/cnn/00/cnn_0003', '0', '3', '-', '-', '-', 'Linda_Hamilton', '*', '(ARGM-NEG*)', '-'], ['selling', 'VBG', '(VP*', 'O', 'bc/cnn/00/cnn_0003', '0', '4', 'sell', '01', '1', 'Linda_Hamilton', '*', '(V*)', '-'], ['medicine', 'NN', '(NP*', 'O', 'bc/cnn/00/cnn_0003', '0', '5', 'medicine', '-', '1', 'Linda_Hamilton', '*', '(ARG1*', '-'], ['or', 'CC', '*', 'O', 'bc/cnn/00/cnn_0003', '0', '6', '-', '-', '-', 'Linda_Hamilton', '*', '*', '-'], ['pharmaceuticals', 'NNS', '*))))', 'O', 'bc/cnn/00/cnn_0003', '0', '7', '-', '-', '-', 'Linda_Hamilton', '*', '*)', '-'], ['/.', '.', '*))', 'O', 'bc/cnn/00/cnn_0003', '0', '8', '-', '-', '-', 'Linda_Hamilton', '*', '*', '-'], [], ['I', 'PRP', '(TOP(S(NP*)', 'O', 'bc/cnn/00/cnn_0003', '0', '0', '-', '-', '-', 'Linda_Hamilton', '(ARG1*)', '*', '*', '(76)'], [\"'m\", 'VBP', '(VP*', 'O', 'bc/cnn/00/cnn_0003', '0', '1', 'be', '01', '1', 'Linda_Hamilton', '(V*)', '*', '*', '-'], ['sort', 'RB', '(PP(ADVP*', 'O', 'bc/cnn/00/cnn_0003', '0', '2', '-', '-', '-', 'Linda_Hamilton', '(ARG2*', '*', '*', '-'], ['of', 'RB', '*)', 'O', 'bc/cnn/00/cnn_0003', '0', '3', '-', '-', '-', 'Linda_Hamilton', '*', '*', '*', '-'], ['about', 'IN', '*', 'O', 'bc/cnn/00/cnn_0003', '0', '4', '-', '-', '-', 'Linda_Hamilton', '*', '*', '*', '-'], ['selling', 'VBG', '(S(VP*', 'O', 'bc/cnn/00/cnn_0003', '0', '5', 'sell', '01', '2', 'Linda_Hamilton', '*', '(V*)', '*', '-'], ['a', 'DT', '(NP(NP*', 'O', 'bc/cnn/00/cnn_0003', '0', '6', '-', '-', '-', 'Linda_Hamilton', '*', '(ARG1*', '*', '-'], ['full', 'JJ', '(ADJP*', 'O', 'bc/cnn/00/cnn_0003', '0', '7', '-', '-', '-', 'Linda_Hamilton', '*', '*', '(ARG2*', '-'], ['body', 'NN', '*)', 'O', 'bc/cnn/00/cnn_0003', '0', '8', 'body', '-', '2', 'Linda_Hamilton', '*', '*', '*)', '-'], ['approach', 'NN', '*)', 'O', 'bc/cnn/00/cnn_0003', '0', '9', 'approach', '02', '3', 'Linda_Hamilton', '*', '*', '(V*)', '-'], ['to', 'IN', '(PP*', 'O', 'bc/cnn/00/cnn_0003', '0', '10', '-', '-', '-', 'Linda_Hamilton', '*', '*', '(ARG1*', '-'], ['wellness', 'NN', '(NP*)))))))', 'O', 'bc/cnn/00/cnn_0003', '0', '11', '-', '-', '-', 'Linda_Hamilton', '*)', '*)', '*)', '-'], ['/.', '.', '*))', 'O', 'bc/cnn/00/cnn_0003', '0', '12', '-', '-', '-', 'Linda_Hamilton', '*', '*', '*', '-'], [], ['Um', 'UH', '(TOP(S(INTJ*)', 'O', 'bc/cnn/00/cnn_0003', '0', '0', '-', '-', '-', 'Linda_Hamilton', '(ARGM-DIS*)', '*', '-'], ['there', 'EX', '(NP*)', 'O', 'bc/cnn/00/cnn_0003', '0', '1', '-', '-', '-', 'Linda_Hamilton', '*', '*', '-'], [\"'s\", 'VBZ', '(VP*', 'O', 'bc/cnn/00/cnn_0003', '0', '2', 'be', '02', '3', 'Linda_Hamilton', '(V*)', '*', '-'], ['a', 'DT', '(NP(NP*', 'O', 'bc/cnn/00/cnn_0003', '0', '3', '-', '-', '-', 'Linda_Hamilton', '(ARG1*', '*', '-'], ['big', 'JJ', '*', 'O', 'bc/cnn/00/cnn_0003', '0', '4', '-', '-', '-', 'Linda_Hamilton', '*', '*', '-'], ['gap', 'NN', '*)', 'O', 'bc/cnn/00/cnn_0003', '0', '5', 'gap', '-', '4', 'Linda_Hamilton', '*', '*', '-'], ['between', 'IN', '(PP*', 'O', 'bc/cnn/00/cnn_0003', '0', '6', '-', '-', '-', 'Linda_Hamilton', '*', '*', '-'], ['those', 'DT', '(NP(NP(NP*)', 'O', 'bc/cnn/00/cnn_0003', '0', '7', '-', '-', '-', 'Linda_Hamilton', '*', '(ARG1*)', '-'], ['that', 'WDT', '(SBAR(WHNP*)', 'O', 'bc/cnn/00/cnn_0003', '0', '8', '-', '-', '-', 'Linda_Hamilton', '*', '(R-ARG1*)', '-'], ['are', 'VBP', '(S(VP*', 'O', 'bc/cnn/00/cnn_0003', '0', '9', 'be', '01', '1', 'Linda_Hamilton', '*', '(V*)', '-'], ['mentally', 'RB', '(ADJP*', 'O', 'bc/cnn/00/cnn_0003', '0', '10', '-', '-', '-', 'Linda_Hamilton', '*', '(ARG2*', '-'], ['ill', 'JJ', '*)))))', 'O', 'bc/cnn/00/cnn_0003', '0', '11', '-', '-', '-', 'Linda_Hamilton', '*', '*)', '-'], ['and', 'CC', '*', 'O', 'bc/cnn/00/cnn_0003', '0', '12', '-', '-', '-', 'Linda_Hamilton', '*', '*', '-'], ['the', 'DT', '(NP*', 'O', 'bc/cnn/00/cnn_0003', '0', '13', '-', '-', '-', 'Linda_Hamilton', '*', '*', '-'], ['general', 'JJ', '*', 'O', 'bc/cnn/00/cnn_0003', '0', '14', '-', '-', '-', 'Linda_Hamilton', '*', '*', '-'], ['population', 'NN', '*)))))', 'O', 'bc/cnn/00/cnn_0003', '0', '15', 'population', '-', '2', 'Linda_Hamilton', '*)', '*', '-'], ['/.', '.', '*))', 'O', 'bc/cnn/00/cnn_0003', '0', '16', '-', '-', '-', 'Linda_Hamilton', '*', '*', '-'], [], ['A', 'DT', '(TOP(FRAG(NP*', 'O', 'bc/cnn/00/cnn_0000', '0', '0', '-', '-', '-', 'speaker1', '*', '*', '*', '(38'], ['much', 'RB', '(ADJP*', 'O', 'bc/cnn/00/cnn_0000', '0', '1', '-', '-', '-', 'speaker1', '*', '*', '*', '-'], ['better', 'JJR', '*))', 'O', 'bc/cnn/00/cnn_0000', '0', '2', '-', '-', '-', 'speaker1', '*', '*', '*', '-'], ['looking', 'VBG', '(VP*', 'O', 'bc/cnn/00/cnn_0000', '0', '3', 'look', '01', '1', 'speaker1', '(V*)', '*', '*', '-'], ['News', 'NNP', '(NP*', 'B-WORK_OF_ART', 'bc/cnn/00/cnn_0000', '0', '4', '-', '-', '-', 'speaker1', '(ARG1*', '*', '*', '-'], ['Night', 'NN', '*)', 'I-WORK_OF_ART', 'bc/cnn/00/cnn_0000', '0', '5', 'night', '-', '1', 'speaker1', '*)', '*', '*', '38)'], ['I', 'PRP', '(SBAR(S(NP*)', 'O', 'bc/cnn/00/cnn_0000', '0', '6', '-', '-', '-', 'speaker1', '*', '(ARG0*)', '*', '(51)'], ['might', 'MD', '(VP*', 'O', 'bc/cnn/00/cnn_0000', '0', '7', '-', '-', '-', 'speaker1', '*', '(ARGM-MOD*)', '*', '-'], ['add', 'VB', '(VP*', 'O', 'bc/cnn/00/cnn_0000', '0', '8', 'add', '02', '1', 'speaker1', '*', '(V*)', '*', '-'], ['as', 'IN', '(SBAR*', 'O', 'bc/cnn/00/cnn_0000', '0', '9', '-', '-', '-', 'speaker1', '*', '(ARGM-CAU*', '*', '-'], ['Paula', 'NNP', '(S(NP*', 'B-PERSON', 'bc/cnn/00/cnn_0000', '0', '10', '-', '-', '-', 'speaker1', '*', '*', '(ARG1*', '(133'], ['Zahn', 'NNP', '*)', 'I-PERSON', 'bc/cnn/00/cnn_0000', '0', '11', '-', '-', '-', 'speaker1', '*', '*', '*)', '133)'], ['sits', 'VBZ', '(VP*', 'O', 'bc/cnn/00/cnn_0000', '0', '12', 'sit', '01', '1', 'speaker1', '*', '*', '(V*)', '-'], ['in', 'IN', '(PP*', 'O', 'bc/cnn/00/cnn_0000', '0', '13', '-', '-', '-', 'speaker1', '*', '*', '(ARG2*', '-'], ['for', 'IN', '(PP*', 'O', 'bc/cnn/00/cnn_0000', '0', '14', '-', '-', '-', 'speaker1', '*', '*', '*', '-'], ['Anderson', 'NNP', '(NP*', 'B-PERSON', 'bc/cnn/00/cnn_0000', '0', '15', '-', '-', '-', 'speaker1', '*', '*', '*', '(71|(105)'], ['and', 'CC', '*', 'O', 'bc/cnn/00/cnn_0000', '0', '16', '-', '-', '-', 'speaker1', '*', '*', '*', '-'], ['Aaron', 'NNP', '*)))))))))))', 'B-PERSON', 'bc/cnn/00/cnn_0000', '0', '17', '-', '-', '-', 'speaker1', '*', '*)', '*)', '(124)|71)'], ['/.', '.', '*))', 'O', 'bc/cnn/00/cnn_0000', '0', '18', '-', '-', '-', 'speaker1', '*', '*', '*', '-'], [], ['They', 'PRP', '(TOP(S(NP*)', 'O', 'bc/cnn/00/cnn_0000', '0', '0', '-', '-', '-', 'speaker1', '(71)'], [\"'re\", 'VBP', '(VP*', 'O', 'bc/cnn/00/cnn_0000', '0', '1', 'be', '-', '1', 'speaker1', '-'], ['both', 'DT', '*', 'O', 'bc/cnn/00/cnn_0000', '0', '2', '-', '-', '-', 'speaker1', '-'], ['off', 'RB', '(ADVP*))', 'O', 'bc/cnn/00/cnn_0000', '0', '3', '-', '-', '-', 'speaker1', '-'], ['/-', '.', '*))', 'O', 'bc/cnn/00/cnn_0000', '0', '4', '-', '-', '-', 'speaker1', '-'], [], ['Look', 'VB', '(TOP(S(VP*', 'O', 'bc/cnn/00/cnn_0000', '0', '0', 'look', '-', '1', 'speaker1', '-'], ['at', 'IN', '(PP*', 'O', 'bc/cnn/00/cnn_0000', '0', '1', '-', '-', '-', 'speaker1', '-'], ['that', 'DT', '(NP*)))', 'O', 'bc/cnn/00/cnn_0000', '0', '2', '-', '-', '-', 'speaker1', '(133)'], ['/.', '.', '*))', 'O', 'bc/cnn/00/cnn_0000', '0', '3', '-', '-', '-', 'speaker1', '-']]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[main.py:533 - data_converter() ] (None,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[main.py:534 - data_converter() ] {'fetchPredictData': True, 'predictData': '../data/sample/ner_test_input.txt', 'loadForPredict': True, 'writeInputToFile': False, 'model': <model.Elmo.ElmoModel object at 0x000001F265323630>, 'sess': <tensorflow.python.client.session.Session object at 0x000001F20D60AE10>, 'saver': <tensorflow.python.training.saver.Saver object at 0x000001F20CABD978>, 'trainedData': [['Yes', 'UH', '(TOP(S(INTJ*)', 'O', 'bc/cnn/00/cnn_0003', '0', '0', '-', '-', '-', 'Linda_Hamilton', '*', '-'], ['they', 'PRP', '(NP*)', 'O', 'bc/cnn/00/cnn_0003', '0', '1', '-', '-', '-', 'Linda_Hamilton', '*', '(15)'], ['did', 'VBD', '(VP*)', 'O', 'bc/cnn/00/cnn_0003', '0', '2', 'do', '01', '-', 'Linda_Hamilton', '(V*)', '-'], ['/.', '.', '*))', 'O', 'bc/cnn/00/cnn_0003', '0', '3', '-', '-', '-', 'Linda_Hamilton', '*', '-'], [], ['and', 'CC', '(TOP(S*', 'O', 'bc/cnn/00/cnn_0003', '0', '0', '-', '-', '-', 'Linda_Hamilton', '(ARGM-DIS*)', '*', '-'], ['they', 'PRP', '(NP*)', 'O', 'bc/cnn/00/cnn_0003', '0', '1', '-', '-', '-', 'Linda_Hamilton', '(ARG1*)', '*', '(15)'], ['were', 'VBD', '(VP*', 'O', 'bc/cnn/00/cnn_0003', '0', '2', 'be', '01', '2', 'Linda_Hamilton', '(V*)', '*', '-'], ['not', 'RB', '*', 'O', 'bc/cnn/00/cnn_0003', '0', '3', '-', '-', '-', 'Linda_Hamilton', '(ARGM-NEG*)', '*', '-'], ['the', 'DT', '(NP(NP*', 'O', 'bc/cnn/00/cnn_0003', '0', '4', '-', '-', '-', 'Linda_Hamilton', '(ARG2*', '(ARG1*', '-'], ['first', 'JJ', '*', 'B-ORDINAL', 'bc/cnn/00/cnn_0003', '0', '5', '-', '-', '-', 'Linda_Hamilton', '*', '*', '-'], ['company', 'NN', '*)', 'O', 'bc/cnn/00/cnn_0003', '0', '6', 'company', '-', '1', 'Linda_Hamilton', '*', '*)', '-'], ['that', 'WDT', '(SBAR(WHNP*)', 'O', 'bc/cnn/00/cnn_0003', '0', '7', '-', '-', '-', 'Linda_Hamilton', '*', '(R-ARG1*)', '-'], ['approached', 'VBD', '(S(VP*', 'O', 'bc/cnn/00/cnn_0003', '0', '8', 'approach', '01', '2', 'Linda_Hamilton', '*', '(V*)', '-'], ['me', 'PRP', '(NP*))))))', 'O', 'bc/cnn/00/cnn_0003', '0', '9', '-', '-', '-', 'Linda_Hamilton', '*)', '(ARG2*)', '(76)'], ['/.', '.', '*))', 'O', 'bc/cnn/00/cnn_0003', '0', '10', '-', '-', '-', 'Linda_Hamilton', '*', '*', '-'], [], ['but', 'CC', '(TOP(S*', 'O', 'bc/cnn/00/cnn_0003', '0', '0', '-', '-', '-', 'Linda_Hamilton', '*', '*', '-'], ['I', 'PRP', '(S(NP*)', 'O', 'bc/cnn/00/cnn_0003', '0', '1', '-', '-', '-', 'Linda_Hamilton', '*', '(ARG0*)', '(76)'], ['am', 'VBP', '(VP*', 'O', 'bc/cnn/00/cnn_0003', '0', '2', 'be', '03', '-', 'Linda_Hamilton', '(V*)', '*', '-'], ['not', 'RB', '*', 'O', 'bc/cnn/00/cnn_0003', '0', '3', '-', '-', '-', 'Linda_Hamilton', '*', '(ARGM-NEG*)', '-'], ['selling', 'VBG', '(VP*', 'O', 'bc/cnn/00/cnn_0003', '0', '4', 'sell', '01', '1', 'Linda_Hamilton', '*', '(V*)', '-'], ['medicine', 'NN', '(NP*', 'O', 'bc/cnn/00/cnn_0003', '0', '5', 'medicine', '-', '1', 'Linda_Hamilton', '*', '(ARG1*', '-'], ['or', 'CC', '*', 'O', 'bc/cnn/00/cnn_0003', '0', '6', '-', '-', '-', 'Linda_Hamilton', '*', '*', '-'], ['pharmaceuticals', 'NNS', '*))))', 'O', 'bc/cnn/00/cnn_0003', '0', '7', '-', '-', '-', 'Linda_Hamilton', '*', '*)', '-'], ['/.', '.', '*))', 'O', 'bc/cnn/00/cnn_0003', '0', '8', '-', '-', '-', 'Linda_Hamilton', '*', '*', '-'], [], ['I', 'PRP', '(TOP(S(NP*)', 'O', 'bc/cnn/00/cnn_0003', '0', '0', '-', '-', '-', 'Linda_Hamilton', '(ARG1*)', '*', '*', '(76)'], [\"'m\", 'VBP', '(VP*', 'O', 'bc/cnn/00/cnn_0003', '0', '1', 'be', '01', '1', 'Linda_Hamilton', '(V*)', '*', '*', '-'], ['sort', 'RB', '(PP(ADVP*', 'O', 'bc/cnn/00/cnn_0003', '0', '2', '-', '-', '-', 'Linda_Hamilton', '(ARG2*', '*', '*', '-'], ['of', 'RB', '*)', 'O', 'bc/cnn/00/cnn_0003', '0', '3', '-', '-', '-', 'Linda_Hamilton', '*', '*', '*', '-'], ['about', 'IN', '*', 'O', 'bc/cnn/00/cnn_0003', '0', '4', '-', '-', '-', 'Linda_Hamilton', '*', '*', '*', '-'], ['selling', 'VBG', '(S(VP*', 'O', 'bc/cnn/00/cnn_0003', '0', '5', 'sell', '01', '2', 'Linda_Hamilton', '*', '(V*)', '*', '-'], ['a', 'DT', '(NP(NP*', 'O', 'bc/cnn/00/cnn_0003', '0', '6', '-', '-', '-', 'Linda_Hamilton', '*', '(ARG1*', '*', '-'], ['full', 'JJ', '(ADJP*', 'O', 'bc/cnn/00/cnn_0003', '0', '7', '-', '-', '-', 'Linda_Hamilton', '*', '*', '(ARG2*', '-'], ['body', 'NN', '*)', 'O', 'bc/cnn/00/cnn_0003', '0', '8', 'body', '-', '2', 'Linda_Hamilton', '*', '*', '*)', '-'], ['approach', 'NN', '*)', 'O', 'bc/cnn/00/cnn_0003', '0', '9', 'approach', '02', '3', 'Linda_Hamilton', '*', '*', '(V*)', '-'], ['to', 'IN', '(PP*', 'O', 'bc/cnn/00/cnn_0003', '0', '10', '-', '-', '-', 'Linda_Hamilton', '*', '*', '(ARG1*', '-'], ['wellness', 'NN', '(NP*)))))))', 'O', 'bc/cnn/00/cnn_0003', '0', '11', '-', '-', '-', 'Linda_Hamilton', '*)', '*)', '*)', '-'], ['/.', '.', '*))', 'O', 'bc/cnn/00/cnn_0003', '0', '12', '-', '-', '-', 'Linda_Hamilton', '*', '*', '*', '-'], [], ['Um', 'UH', '(TOP(S(INTJ*)', 'O', 'bc/cnn/00/cnn_0003', '0', '0', '-', '-', '-', 'Linda_Hamilton', '(ARGM-DIS*)', '*', '-'], ['there', 'EX', '(NP*)', 'O', 'bc/cnn/00/cnn_0003', '0', '1', '-', '-', '-', 'Linda_Hamilton', '*', '*', '-'], [\"'s\", 'VBZ', '(VP*', 'O', 'bc/cnn/00/cnn_0003', '0', '2', 'be', '02', '3', 'Linda_Hamilton', '(V*)', '*', '-'], ['a', 'DT', '(NP(NP*', 'O', 'bc/cnn/00/cnn_0003', '0', '3', '-', '-', '-', 'Linda_Hamilton', '(ARG1*', '*', '-'], ['big', 'JJ', '*', 'O', 'bc/cnn/00/cnn_0003', '0', '4', '-', '-', '-', 'Linda_Hamilton', '*', '*', '-'], ['gap', 'NN', '*)', 'O', 'bc/cnn/00/cnn_0003', '0', '5', 'gap', '-', '4', 'Linda_Hamilton', '*', '*', '-'], ['between', 'IN', '(PP*', 'O', 'bc/cnn/00/cnn_0003', '0', '6', '-', '-', '-', 'Linda_Hamilton', '*', '*', '-'], ['those', 'DT', '(NP(NP(NP*)', 'O', 'bc/cnn/00/cnn_0003', '0', '7', '-', '-', '-', 'Linda_Hamilton', '*', '(ARG1*)', '-'], ['that', 'WDT', '(SBAR(WHNP*)', 'O', 'bc/cnn/00/cnn_0003', '0', '8', '-', '-', '-', 'Linda_Hamilton', '*', '(R-ARG1*)', '-'], ['are', 'VBP', '(S(VP*', 'O', 'bc/cnn/00/cnn_0003', '0', '9', 'be', '01', '1', 'Linda_Hamilton', '*', '(V*)', '-'], ['mentally', 'RB', '(ADJP*', 'O', 'bc/cnn/00/cnn_0003', '0', '10', '-', '-', '-', 'Linda_Hamilton', '*', '(ARG2*', '-'], ['ill', 'JJ', '*)))))', 'O', 'bc/cnn/00/cnn_0003', '0', '11', '-', '-', '-', 'Linda_Hamilton', '*', '*)', '-'], ['and', 'CC', '*', 'O', 'bc/cnn/00/cnn_0003', '0', '12', '-', '-', '-', 'Linda_Hamilton', '*', '*', '-'], ['the', 'DT', '(NP*', 'O', 'bc/cnn/00/cnn_0003', '0', '13', '-', '-', '-', 'Linda_Hamilton', '*', '*', '-'], ['general', 'JJ', '*', 'O', 'bc/cnn/00/cnn_0003', '0', '14', '-', '-', '-', 'Linda_Hamilton', '*', '*', '-'], ['population', 'NN', '*)))))', 'O', 'bc/cnn/00/cnn_0003', '0', '15', 'population', '-', '2', 'Linda_Hamilton', '*)', '*', '-'], ['/.', '.', '*))', 'O', 'bc/cnn/00/cnn_0003', '0', '16', '-', '-', '-', 'Linda_Hamilton', '*', '*', '-'], [], ['A', 'DT', '(TOP(FRAG(NP*', 'O', 'bc/cnn/00/cnn_0000', '0', '0', '-', '-', '-', 'speaker1', '*', '*', '*', '(38'], ['much', 'RB', '(ADJP*', 'O', 'bc/cnn/00/cnn_0000', '0', '1', '-', '-', '-', 'speaker1', '*', '*', '*', '-'], ['better', 'JJR', '*))', 'O', 'bc/cnn/00/cnn_0000', '0', '2', '-', '-', '-', 'speaker1', '*', '*', '*', '-'], ['looking', 'VBG', '(VP*', 'O', 'bc/cnn/00/cnn_0000', '0', '3', 'look', '01', '1', 'speaker1', '(V*)', '*', '*', '-'], ['News', 'NNP', '(NP*', 'B-WORK_OF_ART', 'bc/cnn/00/cnn_0000', '0', '4', '-', '-', '-', 'speaker1', '(ARG1*', '*', '*', '-'], ['Night', 'NN', '*)', 'I-WORK_OF_ART', 'bc/cnn/00/cnn_0000', '0', '5', 'night', '-', '1', 'speaker1', '*)', '*', '*', '38)'], ['I', 'PRP', '(SBAR(S(NP*)', 'O', 'bc/cnn/00/cnn_0000', '0', '6', '-', '-', '-', 'speaker1', '*', '(ARG0*)', '*', '(51)'], ['might', 'MD', '(VP*', 'O', 'bc/cnn/00/cnn_0000', '0', '7', '-', '-', '-', 'speaker1', '*', '(ARGM-MOD*)', '*', '-'], ['add', 'VB', '(VP*', 'O', 'bc/cnn/00/cnn_0000', '0', '8', 'add', '02', '1', 'speaker1', '*', '(V*)', '*', '-'], ['as', 'IN', '(SBAR*', 'O', 'bc/cnn/00/cnn_0000', '0', '9', '-', '-', '-', 'speaker1', '*', '(ARGM-CAU*', '*', '-'], ['Paula', 'NNP', '(S(NP*', 'B-PERSON', 'bc/cnn/00/cnn_0000', '0', '10', '-', '-', '-', 'speaker1', '*', '*', '(ARG1*', '(133'], ['Zahn', 'NNP', '*)', 'I-PERSON', 'bc/cnn/00/cnn_0000', '0', '11', '-', '-', '-', 'speaker1', '*', '*', '*)', '133)'], ['sits', 'VBZ', '(VP*', 'O', 'bc/cnn/00/cnn_0000', '0', '12', 'sit', '01', '1', 'speaker1', '*', '*', '(V*)', '-'], ['in', 'IN', '(PP*', 'O', 'bc/cnn/00/cnn_0000', '0', '13', '-', '-', '-', 'speaker1', '*', '*', '(ARG2*', '-'], ['for', 'IN', '(PP*', 'O', 'bc/cnn/00/cnn_0000', '0', '14', '-', '-', '-', 'speaker1', '*', '*', '*', '-'], ['Anderson', 'NNP', '(NP*', 'B-PERSON', 'bc/cnn/00/cnn_0000', '0', '15', '-', '-', '-', 'speaker1', '*', '*', '*', '(71|(105)'], ['and', 'CC', '*', 'O', 'bc/cnn/00/cnn_0000', '0', '16', '-', '-', '-', 'speaker1', '*', '*', '*', '-'], ['Aaron', 'NNP', '*)))))))))))', 'B-PERSON', 'bc/cnn/00/cnn_0000', '0', '17', '-', '-', '-', 'speaker1', '*', '*)', '*)', '(124)|71)'], ['/.', '.', '*))', 'O', 'bc/cnn/00/cnn_0000', '0', '18', '-', '-', '-', 'speaker1', '*', '*', '*', '-'], [], ['They', 'PRP', '(TOP(S(NP*)', 'O', 'bc/cnn/00/cnn_0000', '0', '0', '-', '-', '-', 'speaker1', '(71)'], [\"'re\", 'VBP', '(VP*', 'O', 'bc/cnn/00/cnn_0000', '0', '1', 'be', '-', '1', 'speaker1', '-'], ['both', 'DT', '*', 'O', 'bc/cnn/00/cnn_0000', '0', '2', '-', '-', '-', 'speaker1', '-'], ['off', 'RB', '(ADVP*))', 'O', 'bc/cnn/00/cnn_0000', '0', '3', '-', '-', '-', 'speaker1', '-'], ['/-', '.', '*))', 'O', 'bc/cnn/00/cnn_0000', '0', '4', '-', '-', '-', 'speaker1', '-'], [], ['Look', 'VB', '(TOP(S(VP*', 'O', 'bc/cnn/00/cnn_0000', '0', '0', 'look', '-', '1', 'speaker1', '-'], ['at', 'IN', '(PP*', 'O', 'bc/cnn/00/cnn_0000', '0', '1', '-', '-', '-', 'speaker1', '-'], ['that', 'DT', '(NP*)))', 'O', 'bc/cnn/00/cnn_0000', '0', '2', '-', '-', '-', 'speaker1', '(133)'], ['/.', '.', '*))', 'O', 'bc/cnn/00/cnn_0000', '0', '3', '-', '-', '-', 'speaker1', '-']]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:05<00:00,  5.07s/it]\n",
      "[main.py:411 - predict() ] Returning predictions :\n",
      "[main.py:412 - predict() ] [['Yes', 'O', 'O'], ['they', 'O', 'O'], ['did', 'O', 'O'], ['/.', 'O', 'O'], [None, None, None], ['and', 'O', 'O'], ['they', 'O', 'O'], ['were', 'O', 'O'], ['not', 'O', 'O'], ['the', 'O', 'O'], ['first', 'B-ORDINAL', 'O'], ['company', 'O', 'O'], ['that', 'O', 'O'], ['approached', 'O', 'O'], ['me', 'O', 'O'], ['/.', 'O', 'O'], [None, None, None], ['but', 'O', 'O'], ['I', 'O', 'O'], ['am', 'O', 'O'], ['not', 'O', 'O'], ['selling', 'O', 'O'], ['medicine', 'O', 'O'], ['or', 'O', 'O'], ['pharmaceuticals', 'O', 'O'], ['/.', 'O', 'O'], [None, None, None], ['I', 'O', 'O'], [\"'m\", 'O', 'O'], ['sort', 'O', 'O'], ['of', 'O', 'O'], ['about', 'O', 'O'], ['selling', 'O', 'O'], ['a', 'O', 'O'], ['full', 'O', 'O'], ['body', 'O', 'O'], ['approach', 'O', 'O'], ['to', 'O', 'O'], ['wellness', 'O', 'O'], ['/.', 'O', 'O'], [None, None, None], ['Um', 'O', 'O'], ['there', 'O', 'O'], [\"'s\", 'O', 'O'], ['a', 'O', 'O'], ['big', 'O', 'O'], ['gap', 'O', 'O'], ['between', 'O', 'O'], ['those', 'O', 'O'], ['that', 'O', 'O'], ['are', 'O', 'O'], ['mentally', 'O', 'O'], ['ill', 'O', 'O'], ['and', 'O', 'O'], ['the', 'O', 'O'], ['general', 'O', 'O'], ['population', 'O', 'O'], ['/.', 'O', 'O'], [None, None, None], ['A', 'O', 'O'], ['much', 'O', 'O'], ['better', 'O', 'O'], ['looking', 'O', 'O'], ['News', 'B-WORK_OF_ART', 'O'], ['Night', 'I-WORK_OF_ART', 'O'], ['I', 'O', 'O'], ['might', 'O', 'O'], ['add', 'O', 'O'], ['as', 'O', 'O'], ['Paula', 'B-PERSON', 'O'], ['Zahn', 'I-PERSON', 'O'], ['sits', 'O', 'O'], ['in', 'O', 'O'], ['for', 'O', 'B-PERSON'], ['Anderson', 'B-PERSON', 'B-PERSON'], ['and', 'O', 'B-PERSON'], ['Aaron', 'B-PERSON', 'B-PERSON'], ['/.', 'O', 'B-PERSON'], [None, None, None], ['They', 'O', 'O'], [\"'re\", 'O', 'O'], ['both', 'O', 'O'], ['off', 'O', 'O'], ['/-', 'O', 'O'], [None, None, None], ['Look', 'O', 'O'], ['at', 'O', 'O'], ['that', 'O', 'O'], ['/.', 'O', 'O'], [None, None, None]]\n"
     ]
    }
   ],
   "source": [
    "predictions = deen.predict('../data/sample/ner_test_input.txt', None, writeInputToFile=False, model=model, sess=sess, saver=saver, trainedData=data['train'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the trained model\n",
    "- Description\n",
    "    * Calculates evaluation metrics on chosen benchmark dataset\n",
    "        - Precision\n",
    "        - Recall\n",
    "        - F1 Score\n",
    "- Returns\n",
    "    * Tuple with metrics (p,r,f1). Each element is float.\n",
    "- Arguments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    "    <thead>\n",
    "        <tr>\n",
    "            <th>Type</th>\n",
    "            <th>Name</th>\n",
    "            <th>Default</th>\n",
    "            <th>Purpose</th>\n",
    "            <th>Required</th>\n",
    "        </tr>\n",
    "    </thead>\n",
    "    <tbody>\n",
    "        <tr>\n",
    "            <td rowspan=\"2\">Standard</td>\n",
    "            <td>predictions</td>\n",
    "            <td>N/A</td>\n",
    "            <td>List of predicted labels</td>\n",
    "            <td>✔</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>groundTruths</td>\n",
    "            <td>N/A</td>\n",
    "            <td>List of ground truth labels</td>\n",
    "            <td>✔</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>args</td>\n",
    "            <td>N/A</td>\n",
    "            <td>None</td>\n",
    "            <td>N/A</td>\n",
    "            <td>✖</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td rowspan=\"2\">kwargs</td>\n",
    "            <td>predsPath</td>\n",
    "            <td>../results/predictions.txt</td>\n",
    "            <td>Location from where to read predictions from</td>\n",
    "            <td>✖</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>groundTruthPath</td>\n",
    "            <td>../results/groundTruths.txt</td>\n",
    "            <td>Location from where to read ground truths from</td>\n",
    "            <td>✖</td>\n",
    "        </tr>\n",
    "    </tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[main.py:443 - evaluate() ] Invoked evaluate method\n",
      "[main.py:444 - evaluate() ] With parameters : \n",
      "[main.py:445 - evaluate() ] ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PERSON', 'B-PERSON', 'B-PERSON', 'B-PERSON', 'B-PERSON', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "[main.py:446 - evaluate() ] ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ORDINAL', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-WORK_OF_ART', 'I-WORK_OF_ART', 'O', 'O', 'O', 'O', 'B-PERSON', 'I-PERSON', 'O', 'O', 'O', 'B-PERSON', 'O', 'B-PERSON', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "[main.py:447 - evaluate() ] (None,)\n",
      "[main.py:448 - evaluate() ] {}\n",
      "[main.py:470 - evaluate() ] Returning evaluation metrics [P, R, F1] :\n",
      "[main.py:471 - evaluate() ] (40.0, 40.0, 40.00000000000001)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(40.0, 40.0, 40.00000000000001)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deen.evaluate([col[3] for col in predictions], [col[3] for col in groundTruth], None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
